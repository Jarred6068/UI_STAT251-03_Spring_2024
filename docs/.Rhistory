#loop over all fileNames
t=1
for(i in Weeks){
for(j in Lectures){
#check is the attendence files exists
fileName = paste(i,j,'Attend.csv', sep='_')
print(paste0('Computing attendence for ', fileName))
does.file.exist = file.exists(paste(path, i, 'Attendence', fileName, sep = "/"))
if (isTRUE(does.file.exist)){
#identify missing students
who.missed.class = who.missed(class.list = snames$Name,
loadpath.quiz = paste(path, i, 'Attendence', fileName, sep = "/"))
attend = rep(1, length(snames$Name))
attend[who.missed.class$missed] = 0
}else{
attend = rep(NA, length(snames$Name))
}
class.att.list = append(class.att.list, list(attend))
lect.names = append(lect.names, paste(i,j, sep='_'))
Sys.sleep(0.05)
setTxtProgressBar(pb, t)
t=t+1
}
}
close(pb)
print('Assembling attendence file')
final.attendence = do.call('cbind.data.frame', class.att.list)
colnames(final.attendence) = c('Student.Name', lect.names)
final.attendence$Days.attended = rowSums(final.attendence[,-c(1:4)], na.rm = T)+5
final.attendence$Total.days.counted = length(which(!is.na(final.attendence[1,-c(1:4, 47)])))-4
temp.score = final.attendence$Days.attended/(final.attendence$Total.days)
final.attendence$Attendance.score = rep(0, length(temp.score))
for(i in 1:length(final.attendence$Total.days)){
if(temp.score[i] > 1){final.attendence$Attendance.score[i] = 1}
else{final.attendence$Attendance.score[i] = temp.score[i]}
}
print('writing to .csv...')
write.csv(final.attendence, file = savepath, row.names = F)
print('finished')
return(final.attendence)
}
#debug(class.attendence)
#debug(who.missed)
fa = class.attendence()
#this part is specific to the class - adds back counted days for students who had acceptable reasons
#to miss class:
add_back_points = function(file, Student.Name, pts){
idx = which(file$Student.Name == Student.Name)
add_back = file$Days.attended[idx] + pts
tempscore = add_back/file$Total.days.counted[idx]
if(tempscore > 1){
file$Attendance.score[idx] = 1
}else{
file$Attendance.score[idx] = tempscore
}
return(file)
}
ABS = c("Kammi Brockman",
"Bethany Rahn",
"Shelby Hobbs",
"Jacob Kachur",
"Ronan Murphy",
"Samuel Bernard",
"Dawson Durham",
"Taiyo Kurata",
"Rachelle Starreveld"
)
num.pts = c(9, 6, 2, 2, 1, 1, 3, 6, 10)
debug(add_back_points)
for(i in 1:length(ABS)){
fa = add_back_points(fa, ABS[i], pts = num.pts[i])
}
write.csv(fa, file = "C:/Users/Bruin/Desktop/GS Academia/TA/Teaching STAT 251/FALL/Attendence_PP.csv",
row.names = F)
add_back
tempscore
#weeks and lecture titles
week.names = paste(rep('Week',15), c(1:15), sep = "_")
lecture.names = c('Lecture_1', 'Lecture_2', 'Lecture_3')
who.missed=function(class.list,
loadpath.quiz = ''){
class.rossiter = class.list
quiz.rossiter = read.csv(loadpath.quiz)
matched = match(class.rossiter, quiz.rossiter$Respondents)
in.class = which(!is.na(matched))
missed.class = which(is.na(matched))
return(list(class.list = class.rossiter, attended = matched, missed = missed.class))
}
class.attendence = function(Weeks = week.names, Lectures = lecture.names,
path = 'C:/Users/Bruin/Desktop/GS Academia/TA/Teaching STAT 251/FALL/',
classnames.Fnames = 'Student_Names_Updated_9_19_2023.csv',
savepath = 'C:/Users/Bruin/Desktop/GS Academia/TA/Teaching STAT 251/FALL/Attendence.csv'){
snames = read.csv(paste(path,classnames.Fnames, sep = '/'))
class.att.list = list(Student.Names = snames$Name)
lect.names = NULL
n_iter = length(Weeks)*length(Lectures)
pb <- txtProgressBar(min = 0,      # Minimum value of the progress bar
max = n_iter, # Maximum value of the progress bar
style = 3,    # Progress bar style (also available style = 1 and style = 2)
width = 50,# Progress bar width. Defaults to getOption("width")
char = "=")
#loop over all fileNames
t=1
for(i in Weeks){
for(j in Lectures){
#check is the attendence files exists
fileName = paste(i,j,'Attend.csv', sep='_')
print(paste0('Computing attendence for ', fileName))
does.file.exist = file.exists(paste(path, i, 'Attendence', fileName, sep = "/"))
if (isTRUE(does.file.exist)){
#identify missing students
who.missed.class = who.missed(class.list = snames$Name,
loadpath.quiz = paste(path, i, 'Attendence', fileName, sep = "/"))
attend = rep(1, length(snames$Name))
attend[who.missed.class$missed] = 0
}else{
attend = rep(NA, length(snames$Name))
}
class.att.list = append(class.att.list, list(attend))
lect.names = append(lect.names, paste(i,j, sep='_'))
Sys.sleep(0.05)
setTxtProgressBar(pb, t)
t=t+1
}
}
close(pb)
print('Assembling attendence file')
final.attendence = do.call('cbind.data.frame', class.att.list)
colnames(final.attendence) = c('Student.Name', lect.names)
final.attendence$Days.attended = rowSums(final.attendence[,-c(1:4)], na.rm = T)+5
final.attendence$Total.days.counted = length(which(!is.na(final.attendence[1,-c(1:4, 47)])))-4
temp.score = final.attendence$Days.attended/(final.attendence$Total.days)
final.attendence$Attendance.score = rep(0, length(temp.score))
for(i in 1:length(final.attendence$Total.days)){
if(temp.score[i] > 1){final.attendence$Attendance.score[i] = 1}
else{final.attendence$Attendance.score[i] = temp.score[i]}
}
print('writing to .csv...')
write.csv(final.attendence, file = savepath, row.names = F)
print('finished')
return(final.attendence)
}
#debug(class.attendence)
#debug(who.missed)
fa = class.attendence()
#this part is specific to the class - adds back counted days for students who had acceptable reasons
#to miss class:
add_back_points = function(file, Student.Name, pts){
idx = which(file$Student.Name == Student.Name)
add_back = file$Days.attended[idx] + pts
tempscore = add_back/file$Total.days.counted[idx]
if(tempscore > 1){
file$Attendance.score[idx] = 1
}else{
file$Attendance.score[idx] = tempscore
}
return(file)
}
ABS = c("Kammi Brockman",
"Bethany Rahn",
"Shelby Hobbs",
"Jacob Kachur",
"Ronan Murphy",
"Samuel Bernard",
"Dawson Durham",
"Taiyo Kurata",
"Rachelle Starreveld"
)
num.pts = c(9, 6, 2, 2, 1, 1, 3, 6, 10)
#debug(add_back_points)
for(i in 1:length(ABS)){
fa = add_back_points(fa, ABS[i], pts = num.pts[i])
}
write.csv(fa, file = "C:/Users/Bruin/Desktop/GS Academia/TA/Teaching STAT 251/FALL/Attendence_PP.csv",
row.names = F)
1*0.5+6*0.2+11*0.3
sum(c(5,5,2.5,5,5,5,5,5,5,5,2.5,5)) - sum(c(5,5,2.5))
150 - sum(c(5,5,2.5,5,5,5,5,5,5,5,2.5,5)) + sum(c(5,5,2.5))
107.5/150
0.13+0.005*17
0.5+0.2*6+0.3*11
1.6/1.9
(5-3)*5
32^2
32*2
2*c(1:10)
c(1:10)^2
8*6
8*2
8*4
8*8
2^c(1,2,3,4)
2^c(3,4,5,6,7,8)
2^c(3,4,5,6,7,8,9)
library(ggplot2)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.width=12, fig.height=8)
#Read in the Data
library(MASS)
library(plyr)
Crops1=read.table('C:/Users/Bruin/Desktop/GS Academia/SEM 3/STAT 517 Machine Learning/Crop Type/WinnipegDataset.txt', header = TRUE, sep = ",")
Crops1$label=as.factor(Crops1$label)
Crops1$label=revalue(Crops1$label, c("1"="corn", "2"="peas","3"="canola","4"="soybeans","5"="oats","6"="wheat","7"="broadleaf"))
idx=dim(Crops1)
Crops.reduced = Crops1[sample(c(1:dim(Crops)[1]), 20000, replace = F)]
Crops.reduced = Crops1[sample(c(1:dim(Crops1)[1]), 20000, replace = F)]
Crops.reduced = Crops1[sample(c(1:dim(Crops1)[1]), 20000, replace = F),]
set.seed(555)
Crops1=read.table('C:/Users/Bruin/Desktop/GS Academia/SEM 3/STAT 517 Machine Learning/Crop Type/WinnipegDataset.txt', header = TRUE, sep = ",")
Crops.reduced = Crops1[sample(c(1:dim(Crops1)[1]), 20000, replace = F),]
write.table(Crops.reduced, quote = F, sep = ',', col.names = T, row.names = F)
getwd()
?write.table
set.seed(555)
Crops1=read.table('C:/Users/Bruin/Desktop/GS Academia/SEM 3/STAT 517 Machine Learning/Crop Type/WinnipegDataset.txt', header = TRUE, sep = ",")
Crops.reduced = Crops1[sample(c(1:dim(Crops1)[1]), 20000, replace = F),]
write.table(Crops.reduced, file =  'C:/Users/Bruin/Desktop/GS Academia/Carpentries/CropData/WinnepegData_small.txt',
quote = F, sep = ',', col.names = T, row.names = F)
summary(as.factor(Crops1$label))
Crops.reduced = Crops1[sample(c(1:dim(Crops1)[1]), 50000, replace = F),]
write.table(Crops.reduced, file =  'C:/Users/Bruin/Desktop/GS Academia/Carpentries/CropData/WinnepegData_small.txt',
quote = F, sep = ',', col.names = T, row.names = F)
1.6/1.9
choose(6,2)
874+350+850
5.5*5
calcg = function(x,y){
pts = ((30-(x-y))*5)/(30*5)
return(pts)
}
calcg(10,2)
calcg = function(x,y){
pts = ((30-(x-y))*5)
grade = pts/(30*5)
return(list(points = pts, grade = grade))
}
calcg(10,2)
calcg(4,2)
calcg(10.5,2)
calcg(6.5,1)
calcg(9.5,1)
calcg(18,1)
calcg(18,2)
calcg(6,1)
calcg(10,0)
calcg(13,1)
calcg(12,1)
calcg(11,1)
calcg(3,2)
calcg(11,1)
calcg(8.5,2)
calcg(3,1)
calcg(8,1)
calcg(13,1)
calcg(7.5,1)
calcg(3,2)
calcg(5,1)
calcg(11,0)
calcg(7,1)
calcg(12.5,1)
calcg(4,0)
calcg(5,2)
calcg(7.5,2)
calcg(4.5,2)
calcg(4,0)
calcg(12,1)
calcg(1,1)
calcg(12,0)
calcg(17,1)
calcg(9,1)
calcg(8.5,2)
calcg(13.5,2)
calcg(13.5,1)
calcg(3,2)
calcg(7.5,1)
calcg(6,1)
calcg(7,0)
calcg(7,1)
calcg(4.5,2)
calcg(8.5,2)
calcg(3,1)
calcg(12,0)
1684*2
3368 - 1500 - 200- 500
total = 1684*2
rent = 1500
car.pmt = 500
utilities = 100
cell.phone = 200
internet = 100
subscripts = 50
groceries = 500
bills = rent+car.pmt+utilities+cell.phone+internet+subscripts+groceries
total - bills
remaining = total - bills
26000*1121
(26000*1121)-13200000
(26000*1121)-13200000-5000000
(38000*1121)-13200000-5000000
library(ggubr)
tab = read.csv('C:/Users/Bruin/Documents/GitHub/HGRN_repo/Simulated Hierarchies/MASTER_results.csv')
longform = cbind.data.frame(metric = as.factor(c(rep('homogeneity', dim(tab)[1]),
rep('completeness', dim(tab)[1]),
rep('NMI', dim(tab)[1]))),
network = as.factor(rep(tab$Network_type, 3)),
input_graph = as.factor(rep(tab$input_graph, 3)),
gamma = as.factor(rep(tab$Gamma, 3)),
resolution_top = as.factor(rep(tab$Resolution_top, 3)),
resolution_middle = as.factor(rep(tab$Resolution_middle, 3)),
Top.stats = c(tab$Top_homogeneity, tab$Top_completeness, tab$Top_NMI),
Mid.stats = c(tab$Middle_homogeneity, tab$Middle_Completeness, tab$Middle_NMI),
Louvain.top = c(tab$Louvain_homogenity_top,
tab$Louvain_completeness_top,
tab$Louvain_NMI_top),
Louvain.middle = c(tab$Louvain_homogenity_middle,
tab$Louvain_completeness_middle,
tab$Louvain_NMI_middle))
longform2 = cbind.data.frame(method = as.factor(c(rep('HCD', dim(longform)[1]),
rep('Louvain', dim(longform)[1]))),
metric = as.factor(rep(c(rep('homogeneity', dim(tab)[1]),
rep('completeness', dim(tab)[1]),
rep('NMI', dim(tab)[1])), 2)),
network = as.factor(rep(tab$Network_type, 6)),
input_graph = as.factor(rep(tab$input_graph, 6)),
gamma = as.factor(rep(tab$Gamma, 6)),
resolution_top = as.factor(rep(tab$Resolution_top, 6)),
resolution_middle = as.factor(rep(tab$Resolution_middle, 6)),
stats.top = c(longform$Top.stats, longform$Louvain.top),
stats.mid = c(longform$Mid.stats, longform$Louvain.top))
ggplot(data = longform2, aes(x = method, y = stats.top, fill = metric))+
geom_boxplot()+
xlab('Method')+
ylab('Top Layer Performance')+
facet_wrap(~network)+
theme_classic2()+
theme(legend.position = 'top', axis.text.x = element_text(angle = 90))
library(ggubr)
tab = read.csv('C:/Users/Bruin/Documents/GitHub/HGRN_repo/Simulated Hierarchies/MASTER_results.csv')
ggplot(data = longform2, aes(x = method, y = stats.top, fill = metric))+
geom_boxplot()+
xlab('Method')+
ylab('Top Layer Performance')+
facet_wrap(~network)+
theme_classic2()+
theme(legend.position = 'top', axis.text.x = element_text(angle = 90))
library(ggpubr)
ggplot(data = longform2, aes(x = method, y = stats.top, fill = metric))+
geom_boxplot()+
xlab('Method')+
ylab('Top Layer Performance')+
facet_wrap(~network)+
theme_classic2()+
theme(legend.position = 'top', axis.text.x = element_text(angle = 90))
View(longform2)
#Louvain Perfomance
ggplot(data = longform, aes(x = input_graph, y = Louvain.top, fill = metric))+
geom_boxplot()+
xlab('Resolution Value')+
ylab('Louvain Performance Top Layer')+
facet_wrap(~network)+
theme_classic2()+
theme(legend.position = 'top')
#Louvain Perfomance
ggplot(data = longform, aes(x = input_graph, y = Louvain.top, fill = metric))+
geom_boxplot()+
xlab('Resolution Value')+
ylab('Louvain Performance Top Layer')+
facet_wrap(~network)+
theme_classic2()+
theme(legend.position = 'top', axis.text.x = element_text(angle = 90))
#Louvain Perfomance
ggplot(data = longform, aes(x = input_graph, y = Louvain.top, fill = metric))+
geom_boxplot()+
xlab('Input Graph')+
ylab('Louvain Performance Top Layer')+
facet_wrap(~network)+
theme_classic2()+
theme(legend.position = 'top', axis.text.x = element_text(angle = 90))
ggplot(data = longform, aes(x = input_graph, y = Louvain.middle, fill = metric))+
geom_boxplot()+
xlab('Resolution Value')+
ylab('Louvain Performance Middle Layer')+
facet_wrap(~network)+
theme_classic2()+
theme(legend.position = 'top', axis.text.x = element_text(angle = 90))
ggplot(data = longform2, aes(x = method, y = stats.mid, fill = metric))+
geom_boxplot()+
xlab('Method')+
ylab('Middle Layer Performance')+
facet_wrap(~network)+
theme_classic2()+
theme(legend.position = 'top', axis.text.x = element_text(angle = 90))
ggplot(data = longform2, aes(x = method, y = stats.mid, fill = metric))+
geom_boxplot()+
xlab('Method')+
ylab('Middle Layer Performance')+
facet_wrap(~input_graph)+
theme_classic2()+
theme(legend.position = 'top', axis.text.x = element_text(angle = 90))
ggplot(data = longform2, aes(x = method, y = stats.top, fill = metric))+
geom_boxplot()+
xlab('Method')+
ylab('Top Layer Performance')+
facet_wrap(~input_graph)+
theme_classic2()+
theme(legend.position = 'top', axis.text.x = element_text(angle = 90))
#plotted over gamma parameter
ggplot(data = longform, aes(x = gamma, y = Top.stats, fill = metric))+
geom_boxplot()+
xlab('Weight Applied to Reconstruction Loss')+
ylab('Performance Top Layer')+
facet_wrap(~network)+
theme_classic2()+
theme(legend.position = 'top')
ggplot(data = longform, aes(x = gamma, y = Mid.stats, fill = metric))+
geom_boxplot()+
xlab('Weight Applied to Reconstruction Loss')+
ylab('Performance Middle Layer')+
facet_wrap(~network)+
theme_classic2()+
theme(legend.position = 'top')
ggplot(data = longform, aes(x = gamma, y = Mid.stats, fill = metric))+
geom_boxplot()+
xlab('Weight Applied to Reconstruction Loss')+
ylab('Performance Middle Layer')+
facet_wrap(~network)+
theme_classic2()+
theme(legend.position = 'top')
ggplot(data = longform2, aes(x = method, y = stats.mid, fill = metric))+
geom_boxplot()+
xlab('Method')+
ylab('Middle Layer Performance')+
facet_wrap(~network)+
theme_classic2()+
theme(legend.position = 'top', axis.text.x = element_text(angle = 90))
#plotted over gamma parameter
ggplot(data = longform, aes(x = gamma, y = Top.stats, fill = metric))+
geom_boxplot()+
xlab('Weight Applied to Reconstruction Loss')+
ylab('Performance Top Layer')+
facet_wrap(~network)+
theme_classic2()+
theme(legend.position = 'top')
ggplot(data = longform, aes(x = gamma, y = Mid.stats, fill = metric))+
geom_boxplot()+
xlab('Weight Applied to Reconstruction Loss')+
ylab('Performance Middle Layer')+
facet_wrap(~network)+
theme_classic2()+
theme(legend.position = 'top')
11500
11500/10
1142 - 850
1142*2
1142*2- 1700
#Set our working directory.
#This helps avoid confusion if our working directory is
#not our site because of other projects we were
#working on at the time.
setwd("C:/Users/Bruin/Documents/GitHub/UI_STAT251-03_Spring_2024/docs/")
#render your sweet site.
rmarkdown::render_site()
faithful$eruptions
hist(faithful$eruptions)
h = hist(faithful$eruptions)
h$counts
h$breaks
min(faithful$eruptions)
h$counts
h$counts/sum(h$counts)
round(h$counts/sum(h$counts),1)
round(h$counts/sum(h$counts),2)
cumsum(round(h$counts/sum(h$counts),2))
#Set our working directory.
#This helps avoid confusion if our working directory is
#not our site because of other projects we were
#working on at the time.
setwd("C:/Users/Bruin/Documents/GitHub/UI_STAT251-03_Spring_2024/docs/")
#render your sweet site.
rmarkdown::render_site()
round_any
?round_any
??round_any
plyr::round_any(2.3, 0.5)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.width=8, fig.height=8, fig.pos = "H")
#knitr::opts_chunk$set(list(echo = FALSE, eval = FALSE))
library(kableExtra)
library(knitr)
library(latex2exp)
library(gridExtra)
library(ggpubr)
library(ggthemes)
library(plyr)
path = 'C:/Users/Bruin/Desktop/GS Academia/TA/Teaching STAT 251/FALL/Week_1/'
set.seed(123)
#<span style="color: red;">text</span>
set.seed(123)
#fldata = read.csv(paste0(path, 'fl_student_survey.csv'))
#fldata$gpa_rounded = round_any(fldata$high_sch_GPA, 0.5)
x_raw = c(2.0, 2.1, 2.3, 2.8, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0,3.0, 3.0, 3.0, 3.1, 3.2, 3.3, 3.3, 3.4,  3.4, 3.4,3.4, 3.5, 3.5, 3.5, 3.5, 3.6, 3.6, 3.7, 3.7, 3.8,3.8, 3.8, 3.8, 4.0, 4.0)
x=round_any(x_raw, 0.5)
hsGPA_values = sort(unique(x))
hsGPA_freq = summary(as.factor(x))
hsGPA_RF = hsGPA_freq/sum(hsGPA_freq)
hsGPA_cRF = cumsum(hsGPA_RF)
FT = cbind.data.frame(GPA = hsGPA_values,
Frequency = hsGPA_freq,
`Relative frequency` = round(hsGPA_RF,2),
`Cumulative RF` = round(hsGPA_cRF, 2))
kable(FT, format = 'html', digits = 2, row.names = F, booktabs = T)%>%
kable_classic(full_width = F, html_font = "Cambria")%>%kable_styling(bootstrap_options = 'striped')
