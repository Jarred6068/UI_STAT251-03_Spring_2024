m = 0.015 #desired margin of error
p = 0.24 #expected proportion of e-cigarette use based on Saudi Study
confidence.lvl = 0.95
alpha = 1 - confidence.lvl
z = qnorm(1 - alpha/2) #standard score for confidence level of 95%
n = round((z^2*p*(1-p))/m^2) # compute sample size - round to nearest whole number
# a sample size of approximately
print(paste0('n = ', n, ' observations'))
#are needed to achieve the desire confidence level and margin of error
m = 0.04 #desired margin of error
p = 0.15 #expected proportion of infertile couples based on previous studies
confidence.lvl = 0.99
alpha = 1 - confidence.lvl
z = qnorm(1 - alpha/2) #standard score for confidence level of 99%
n = round((z^2*p*(1-p))/m^2) # compute sample size - round to nearest whole number
# a sample size of approximately
print(paste0('n = ', n, ' observations'))
#are needed to achieve the desire confidence level and margin of error
test.type = 'two.tailed'
null.value = 0.5
sample.size = 100
estimated.proportion = 40/100
significance.lvl = 0.1
one.sample.prop.test(p0 = null.value,
phat = estimated.proportion,
n = sample.size,
alpha = significance.lvl,
test = test.type,
verbose = T)
citation(package = 'surveydata')
set.seed(555)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.width=12, fig.height=10, fig.pos = "H")
#knitr::opts_chunk$set(list(echo = FALSE, eval = FALSE))
library(kableExtra)
library(knitr)
library(latex2exp)
library(gridExtra)
library(ggpubr)
library(ggthemes)
library(plyr)
mainpath = 'C:/Users/Bruin/Documents/GitHub/UI_STAT251-03_Spring_2024/docs/Data/'
wmpath = 'C:/Users/Bruin/Desktop/GS Academia/MS_Stat/SEM 2/STAT 519/PROJ 1/watermelon/simulated datasets/ wawamelon/WaterMelonMaster.csv'
whiskpath = 'C:/Users/Bruin/Desktop/GS Academia/MS_Stat/SEM 2/STAT 519/PROJ 1/Whiskers/SimSealData/whiskerMaster.csv'
datapath = 'C:/Users/Bruin/Documents/GitHub/UI_STAT251-03_Spring_2024/docs/Data/'
#<span style="color: red;"></span>
herbivore_data <- data.frame(
Observation = 1:12,
`Number of Tracks In Fertilized plots` = c(15, 12, 18, 14, 16, 13, 17, 14, 19, 15, 11, 16),
`Number of Tracks In Control Plots` = c(10, 9, 11, 8, 12, 10, 11, 9, 13, 10, 8, 12),
`Difference` = rep('',12),
`Sign` = rep('',12)
)
kable(tab, format = 'html', digits = 2,
row.names = F, booktabs = T, escape = F)%>%
kable_classic(full_width = F, html_font = "Cambria")%>%kable_styling(bootstrap_options = 'striped')
herbivore_data <- data.frame(
Observation = 1:12,
`Number of Tracks In Fertilized plots` = c(15, 12, 18, 14, 16, 13, 17, 14, 19, 15, 11, 16),
`Number of Tracks In Control Plots` = c(10, 9, 11, 8, 12, 10, 11, 9, 13, 10, 8, 12),
`Difference` = rep('',12),
`Sign` = rep('',12)
)
kable(herbivore_data, format = 'html', digits = 2,
row.names = F, booktabs = T, escape = F)%>%
kable_classic(full_width = F, html_font = "Cambria")%>%kable_styling(bootstrap_options = 'striped')
herbivore_data <- cbind.data.frame(
Observation = 1:12,
`Number of Tracks In Fertilized plots` = c(15, 12, 18, 14, 16, 13, 17, 14, 19, 15, 11, 16),
`Number of Tracks In Control Plots` = c(10, 9, 11, 8, 12, 10, 11, 9, 13, 10, 8, 12),
`Difference` = rep('',12),
`Sign` = rep('',12)
)
kable(herbivore_data, format = 'html', digits = 2,
row.names = F, booktabs = T, escape = F)%>%
kable_classic(full_width = F, html_font = "Cambria")%>%kable_styling(bootstrap_options = 'striped')
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
library(kableExtra)
library(ggplot2)
library(ggthemes)
library(ggpubr)
library(latex2exp)
library(gganimate)
path = 'C:/Users/Bruin/Documents/GitHub/UI_STAT251-03_Spring_2024/docs/Data/'
##stat pack
source('C:/Users/Bruin/Documents/GitHub/UI_STAT251-03_Spring_2024/docs/misc/stat251_tools.R')
set.seed(123)
sc.matchup = c('Alabama', 'Kentucky', 'Arkansas', 'Tenessee', 'Texas A&M','Tenessee', 'LSU','Presbyterian', 'UNC', 'Indiana', 'Oregon State','NC State')
sc = c(78, 70, 79, 88, 91, 79, 74, 79, 76, 98, 103, 72)
spacer = rep('', 12)
io.matchup = c('Indiana','Illinois','Minnesota', 'Ohio State', 'Penn State', 'Michigan', 'Nebraska', 'Holy Cross', 'West Virginia', 'Colorado', 'LSU', 'UConn')
io = c(71, 94, 89, 64, 91, 94, 95, 95, 93, 108, 101, 69)
df1 = cbind.data.frame(`South Carolina` = sc,
`Matchup` = sc.matchup,
`-` = spacer,
`Iowa` = io,
`Matchup` = io.matchup)
kable(df1, format = 'html', digits = 2,
row.names = F, booktabs = T, escape = F)%>%
kable_classic(full_width = F, html_font = "Cambria")%>%kable_styling(bootstrap_options = 'striped')
io.matchup = rev(c('Indiana','Illinois','Minnesota', 'Ohio State', 'Penn State', 'Michigan', 'Nebraska', 'Holy Cross', 'West Virginia', 'Colorado', 'LSU', 'UConn'))
set.seed(123)
sc.matchup = c('Alabama', 'Kentucky', 'Arkansas', 'Tenessee', 'Texas A&M','Tenessee', 'LSU','Presbyterian', 'UNC', 'Indiana', 'Oregon State','NC State')
sc = c(78, 70, 79, 88, 91, 79, 74, 79, 76, 98, 103, 72)
spacer = rep('', 12)
io.matchup = rev(c('Indiana','Illinois','Minnesota', 'Ohio State', 'Penn State', 'Michigan', 'Nebraska', 'Holy Cross', 'West Virginia', 'Colorado', 'LSU', 'UConn'))
io = c(71, 94, 89, 64, 91, 94, 95, 95, 93, 108, 101, 69)
df = cbind.data.frame(Population = c('Iowa', 'South Carolina'),
`Population Mean` = c('$\\mu_1$', '$\\mu_2$'),
`Sample Size` = c('$n_1 = 12$', '$n_2 = 12$'),
`Sample Mean` = c(round(mean(io), 2), round(mean(sc), 2)),
`Sample Stdev` = c(round(sd(io), 2), round(sd(sc), 2)))
kable(df, format = 'html', digits = 2,
row.names = F, booktabs = T, escape = F)%>%
kable_classic(full_width = F, html_font = "Cambria")%>%kable_styling(bootstrap_options = 'striped')
set.seed(123)
sc.matchup = rev(c('Alabama', 'Kentucky', 'Arkansas', 'Tenessee', 'Texas A&M','Tenessee', 'LSU','Presbyterian', 'UNC', 'Indiana', 'Oregon State','NC State'))
sc = c(78, 70, 79, 88, 91, 79, 74, 79, 76, 98, 103, 72)
spacer = rep('', 12)
io.matchup = rev(c('Indiana','Illinois','Minnesota', 'Ohio State', 'Penn State', 'Michigan', 'Nebraska', 'Holy Cross', 'West Virginia', 'Colorado', 'LSU', 'UConn'))
io = c(71, 94, 89, 64, 91, 94, 95, 95, 93, 108, 101, 69)
df1 = cbind.data.frame(`South Carolina` = sc,
`Matchup` = sc.matchup,
`-` = spacer,
`Iowa` = io,
`Matchup` = io.matchup)
kable(df1, format = 'html', digits = 2,
row.names = F, booktabs = T, escape = F)%>%
kable_classic(full_width = F, html_font = "Cambria")%>%kable_styling(bootstrap_options = 'striped')
two.sample.t.test(0, 88.67, 82.25, 13.47, 10.45, 15, 15, test.type = 'two.tail')
two.sample.t.test(0, 88.67, 82.25, 13.47, 10.45, 15, 15, test = 'two.tail')
two.sample.t.test(0, 88.67, 82.25, 13.47, 10.45, 15, 15, test = 'two.tail', pooling = T)
two.sample.t.test(0, 88.67, 82.25, 13.47, 10.45, 15, 15, test = 'two.tail', pooling = 'approx.unpooled')
(75 - 88.67)/(13.47/sqrt(15))
two.sample.t.test(0, 90.67, 80.40, 14.21, 10.57, 15, 15, test = 'two.tail', pooling = 'approx.unpooled')
two.sample.t.test(0, 90.67, 80.40, 14.21, 10.57, 15, 15, test = 'two.tail', pooling = 'npooled')
two.sample.t.test(0, 90.67, 80.40, 14.21, 10.57, 15, 15, test = 'two.tail', pooling = 'pooled')
#Set our working directory.
#This helps avoid confusion if our working directory is
#not our site because of other projects we were
#working on at the time.
setwd("C:/Users/Bruin/Documents/GitHub/UI_STAT251-03_Spring_2024/docs/")
#render your sweet site.
rmarkdown::render_site()
two.sample.t.test(0, 90.67, 80.40, 14.21, 10.57, 15, 15, test = 'two.tail', pooling = 'approx.unpooled')
1-pt(2.2459, 14)
1-pt(2.2459, 14)
set.seed(123)
sc.matchup = rev(c('UConn','Tenessee','Georgia','Alabama', 'Kentucky', 'Arkansas', 'Tenessee', 'Texas A&M','Tenessee', 'LSU','Presbyterian', 'UNC', 'Indiana', 'Oregon State','NC State'))
sc = c(78, 70, 79, 88, 91, 79, 74, 79, 76, 98, 103, 72, 70, 66, 83)
spacer = rep('', 15)
io.matchup = rev(c('Penn State','Nebraska','Michigan','Indiana','Illinois','Minnesota', 'Ohio State', 'Penn State', 'Michigan', 'Nebraska', 'Holy Cross', 'West Virginia', 'Colorado', 'LSU', 'UConn'))
io = c(71, 94, 89, 64, 91, 94, 95, 95, 93, 108, 101, 69, 106, 79, 111)
df = cbind.data.frame(Population = c('Iowa', 'South Carolina'),
`Population Mean` = c('$\\mu_1$', '$\\mu_2$'),
`Sample Size` = c('$n_1 = 15$', '$n_2 = 15$'),
`Sample Mean` = c(round(mean(io), 2), round(mean(sc), 2)),
`Sample Stdev` = c(round(sd(io), 2), round(sd(sc), 2)))
kable(df, format = 'html', digits = 2,
row.names = F, booktabs = T, escape = F)%>%
kable_classic(full_width = F, html_font = "Cambria")%>%kable_styling(bootstrap_options = 'striped')
two.sample.t.test(0, 90.67, 80.40, 14.21, 10.57, 15, 15, test = 'two.tail', pooling = 'approx.unpooled')
1-pt(2.246, 14)
2*0.0207
90.67 - 80.40
(75 - 90.67)/14.57
(75 - 90.67)/(14.57/sqrt(15))
set.seed(123)
df = cbind.data.frame(`Group` = c('Company 1', 'Company 2'),
`Number of customers` = c(174, 355),
`Sample Mean Rating` = c(4.2, 3.8),
`Sample Stdev` = c(0.8, 1.1))
kable(df, format = 'html', digits = 2,
row.names = F, booktabs = T, escape = F)%>%
kable_classic(full_width = F, html_font = "Cambria")%>%kable_styling(bootstrap_options = 'striped')
two.sample.t.SE(0.8, 1.1, 174, 355)
1.96*two.sample.t.SE(0.8, 1.1, 174, 355)
0.4 - 1.96*two.sample.t.SE(0.8, 1.1, 174, 355)
0.4 + 1.96*two.sample.t.SE(0.8, 1.1, 174, 355)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.width=12, fig.height=8, fig.pos = "H")
#knitr::opts_chunk$set(list(echo = FALSE, eval = FALSE))
library(kableExtra)
library(knitr)
library(latex2exp)
library(gridExtra)
d.vec = c(2,4,6,8,10,12,15)
library(MRGN)
library(ggpubr)
library(ggthemes)
# results.lists = list()
# selected.confs.list = list()
# true.confs.list = list()
# params.lists = list()
color.codes = c("#0073C2FF","#EFC000FF")
hit.miss.mat = as.data.frame(matrix(0, nrow = length(d.vec), ncol = 3))
colnames(hit.miss.mat) = c("TP","FP","FN")
pool.size = NULL
for(i in 1:length(d.vec)){
conf.mat = loadRData(file = paste0("C:/Users/Bruin/Documents/GitHub/MRGN_extra/Simulations/GMACvMRGN_sim/simulated_data_all_conf_types/GMAC_validation_SIM/gmac_valid_sim__conf_mat_numconfs_",d.vec[i],".RData"))
pool.size[i] = dim(conf.mat)[2]
params.lists = loadRData(paste0(file = "C:/Users/Bruin/Documents/GitHub/MRGN_extra/Simulations/GMACvMRGN_sim/simulated_data_all_conf_types/GMAC_validation_SIM/gmac_valid_sim_parameters_numcomfs_",d.vec[i],".RData"))
null.mods.ix = which(params.lists$model == "model0")
true.confs.list = lapply(loadRData(file = paste0("C:/Users/Bruin/Documents/GitHub/MRGN_extra/Simulations/GMACvMRGN_sim/simulated_data_all_conf_types/GMAC_validation_SIM/gmac_valid_sim_simdata_numconfs_",d.vec[i], ".RData")), function(x) colnames(x$data)[-c(1:3)])[null.mods.ix]
results.lists = loadRData(file =  paste0("C:/Users/Bruin/Documents/GitHub/MRGN_extra/Simulations/GMACvMRGN_sim/simulated_data_all_conf_types/GMAC_validation_SIM/gmac_valid_sim_cis_results_numconfs_",d.vec[i],".RData"))
selected.confs.list = apply(results.lists$cov.indicator.list[null.mods.ix,], 1, function(x,y) colnames(y)[which(x == 1)], y = conf.mat)
match.list = lapply(c(1:length(selected.confs.list)), function(x,y,z) match(y[[x]], z[[x]]),
y = selected.confs.list, z = true.confs.list)
TP = unlist(lapply(match.list, function(x) length(na.omit(x))))
FP = unlist(lapply(match.list, function(x) if(any(is.na(x))) length(which(is.na(x))) else 0))
match.list2 = lapply(c(1:length(selected.confs.list)), function(x,y,z) match(y[[x]], z[[x]]),
y = true.confs.list, z = selected.confs.list)
FN = unlist(lapply(match.list2, function(x) if(any(is.na(x))) length(which(is.na(x))) else 0))
hit.miss.mat[i, ] = cbind.data.frame(mean(TP), mean(FP), mean(FN))
}
x = loadRData("C:/Users/Bruin/Documents/GitHub/MRGN_extra/Simulations/GMACvMRGN_sim/simulated_data_all_conf_types/GMAC_validation_SIM/gmac_valid_summary_results_table.RData")
x$`Significance Cutoff For Mediation` = x$Cutoff
final.mat = cbind.data.frame(x, rbind(hit.miss.mat, hit.miss.mat), pool.size = rep(pool.size,2))
A = ggplot(aes(x = `Simulated Confs`, y = `Type I Error`, color = `Significance Cutoff For Mediation`,
linetype = `Significance Cutoff For Mediation`), data = final.mat)+
scale_x_continuous(breaks = d.vec)+
scale_y_continuous(breaks = seq(0, 0.5, 0.1))+
geom_line(size = 1.5)+
geom_point(size = 3)+
theme_hc()+
scale_fill_manual(values = color.codes)+
scale_color_manual(values = color.codes)+
xlab('Number of Confounders Simulated Per Trio')+
ylab('Type I Error Rate (Under The Null Model)')
B = ggplot(aes(x = FN, y = `Type I Error`, color = `Significance Cutoff For Mediation`,
linetype = `Significance Cutoff For Mediation`), data = final.mat)+
scale_x_continuous(breaks = seq(0, max(final.mat$FN), 0.3))+
scale_y_continuous(breaks = seq(0, 0.5, 0.1))+
geom_line(size = 1.5)+
geom_point(size = 3)+
theme_hc()+
scale_fill_manual(values = color.codes)+
scale_color_manual(values = color.codes)+
xlab('Mean Number of False Negative Confounders')+
ylab('Type I Error Rate (Under The Null Model)')
C = ggplot(aes(x = pool.size, y = FN), data = final.mat)+
scale_x_continuous(breaks = d.vec*200)+
scale_y_continuous(breaks = seq(0, max(final.mat$FN), 0.3))+
geom_line(size = 1.5)+
geom_point(size = 3)+
theme_hc()+
xlab('Column Dimension of the Confounder Pool')+
ylab('Mean Number of False Negative Confounders')
D = ggplot(aes(x = pool.size, y = FP), data = final.mat)+
scale_x_continuous(breaks = d.vec*200)+
scale_y_continuous(breaks = seq(0, max(final.mat$FP), 0.3))+
geom_line(size = 1.5)+
geom_point(size = 3)+
theme_hc()+
xlab('Column Dimension of the Confounder Pool')+
ylab('Mean Number of False Positive Confounders')
final.p = ggarrange(A,B,C,D, labels = c("A","B","C","D"), nrow = 2, ncol = 2, common.legend = T,
hjust = -5, vjust = 2.5)
plot(final.p)
x = loadRData("C:/Users/Bruin/Documents/GitHub/MRGN_extra/Simulations/GMACvMRGN_sim/simulated_data_all_conf_types/GMAC_validation_SIM/gmac_valid_summary_results_table.RData")
x
x$`Significance Cutoff For Mediation` = x$Cutoff
x
library(MRGN)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.width=12, fig.height=8, fig.pos = "H")
#knitr::opts_chunk$set(list(echo = FALSE, eval = FALSE))
library(kableExtra)
library(knitr)
library(latex2exp)
library(gridExtra)
library("MRGN")
library("qvalue")
library("caret")
#read in helper functions
source('C:/Users/Bruin/Documents/GitHub/MRGN_extra/Simulations/GMACvMRGN_sim/simulated_data_all_conf_types/sim_write_up_files/MRGN_write_up_helper_functions.R')
#======================================================================================
#This section compares MRGN, MRPC, and GMAC using the GMAC procedure for confounder selection and filtering
#simulations include between 1-15 confounders with 1 intermediate and 1 common child variable
#1500 trios with approximately 10% having a minor allele frequency <0.05
#read in simulation data
params=loadRData(file="C:/Users/Bruin/Documents/GitHub/MRGN_extra/Simulations/GMACvMRGN_sim/simulated_data_all_conf_types/sim_set_3_data/mrpc_v_mrgn_v_gmac_5k_params_all_mods_conf_types.RData")
master.table = loadRData(file="C:/Users/Bruin/Documents/GitHub/MRGN_extra/Simulations/GMACvMRGN_sim/simulated_data_all_conf_types/sim_set_3_data/master_table_all_confs_all_mods.RData")
#write.csv(master.table, "C:/Users/Bruin/Documents/GitHub/MRGN_extra/Manuscript/SuppTables/summary.table.all.trios.15confs.csv", row.names = F)
gmac.trans = loadRData(file="C:/Users/Bruin/Documents/GitHub/MRGN_extra/Simulations/GMACvMRGN_sim/simulated_data_all_conf_types/sim_set_3_data/gmac_5k_trans_results_all_all_mods_conf_types_preproc.RData")
gmac.cis=loadRData(file="C:/Users/Bruin/Documents/GitHub/MRGN_extra/Simulations/GMACvMRGN_sim/simulated_data_all_conf_types/sim_set_3_data/gmac_5k_cis_results_all_mods_all_conf_types_proproc.RData")
mrgn.inf=loadRData("C:/Users/Bruin/Documents/GitHub/MRGN_extra/Simulations/GMACvMRGN_sim/simulated_data_all_conf_types/sim_set_3_data/int_and_child_filtered_data/mrgn_5k_inf_results_all_confs_filtered_all_mods.RData")
#mrgn.reg.res=loadRData(file="C:/Users/Bruin/Documents/GitHub/MRGN_extra/Simulations/GMACvMRGN_sim/simulated_data_all_conf_types/sim_set_3_data/int_and_child_filtered_data/mrgn_5k_regres_results_all_confs_filtered_all_mods.RData")
mrpc.inf=loadRData(file="C:/Users/Bruin/Documents/GitHub/MRGN_extra/Simulations/GMACvMRGN_sim/simulated_data_all_conf_types/sim_set_3_data/int_and_child_filtered_data/mrpc_5k_small_results_all_confs_filtered_all_mods.RData")
datasets=loadRData(file="C:/Users/Bruin/Documents/GitHub/MRGN_extra/Simulations/GMACvMRGN_sim/simulated_data_all_conf_types/sim_set_3_data/mrgn_v_gmac_v_mrpc_5k_datasets_all_mods_conf_types.RData")
conf.list.mrgn=loadRData(file="C:/Users/Bruin/Documents/GitHub/MRGN_extra/Simulations/GMACvMRGN_sim/simulated_data_all_conf_types/sim_set_3_data/int_and_child_filtered_data/mrgn_5k_conf_list_all_confs_filtered_all_mods.RData")
#conf.list.mrpc = loadRData(file="C:/Users/Bruin/Documents/GitHub/MRGN_extra/Simulations/GMACvMRGN_sim/simulated_data_all_conf_types/sim_set_3_data/int_and_child_filtered_data/mrpc_5k_conf_list_all_confs_filtered_all_mods.RData")
conf.mat = loadRData(file = "C:/Users/Bruin/Documents/GitHub/MRGN_extra/Simulations/GMACvMRGN_sim/simulated_data_all_conf_types/sim_set_3_data/mrgn_v_gmac_v_mrpc_5k_datasets_all_mods_conf_types_conf_mat.RData")
#======================================================================================
#read simulation results for conf selection with no FDR (selected at alpha < 0.01)
conf.list.alpha01 = loadRData('C:/Users/Bruin/Documents/GitHub/MRGN_extra/Simulations/GMACvMRGN_sim/simulated_data_all_conf_types/sim_set_3_data/int_and_child_filtered_data/alpha_01_selected_confs_results/MRGN_15confs_liberal_alpha01_conf_list.RData')
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.width=12, fig.height=8, fig.pos = "H")
#knitr::opts_chunk$set(list(echo = FALSE, eval = FALSE))
library(kableExtra)
library(knitr)
library(latex2exp)
library(gridExtra)
library("MRGN")
library("qvalue")
library("caret")
#read in helper functions
source('C:/Users/Bruin/Documents/GitHub/MRGN_extra/Simulations/GMACvMRGN_sim/simulated_data_all_conf_types/sim_write_up_files/MRGN_write_up_helper_functions.R')
#======================================================================================
#This section compares MRGN, MRPC, and GMAC using the GMAC procedure for confounder selection and filtering
#simulations include between 1-15 confounders with 1 intermediate and 1 common child variable
#1500 trios with approximately 10% having a minor allele frequency <0.05
#read in simulation data
params=loadRData(file="C:/Users/Bruin/Documents/GitHub/MRGN_extra/Simulations/GMACvMRGN_sim/simulated_data_all_conf_types/sim_set_3_data/mrpc_v_mrgn_v_gmac_5k_params_all_mods_conf_types.RData")
master.table = loadRData(file="C:/Users/Bruin/Documents/GitHub/MRGN_extra/Simulations/GMACvMRGN_sim/simulated_data_all_conf_types/sim_set_3_data/master_table_all_confs_all_mods.RData")
#write.csv(master.table, "C:/Users/Bruin/Documents/GitHub/MRGN_extra/Manuscript/SuppTables/summary.table.all.trios.15confs.csv", row.names = F)
gmac.trans = loadRData(file="C:/Users/Bruin/Documents/GitHub/MRGN_extra/Simulations/GMACvMRGN_sim/simulated_data_all_conf_types/sim_set_3_data/gmac_5k_trans_results_all_all_mods_conf_types_preproc.RData")
gmac.cis=loadRData(file="C:/Users/Bruin/Documents/GitHub/MRGN_extra/Simulations/GMACvMRGN_sim/simulated_data_all_conf_types/sim_set_3_data/gmac_5k_cis_results_all_mods_all_conf_types_proproc.RData")
mrgn.inf=loadRData("C:/Users/Bruin/Documents/GitHub/MRGN_extra/Simulations/GMACvMRGN_sim/simulated_data_all_conf_types/sim_set_3_data/int_and_child_filtered_data/mrgn_5k_inf_results_all_confs_filtered_all_mods.RData")
#mrgn.reg.res=loadRData(file="C:/Users/Bruin/Documents/GitHub/MRGN_extra/Simulations/GMACvMRGN_sim/simulated_data_all_conf_types/sim_set_3_data/int_and_child_filtered_data/mrgn_5k_regres_results_all_confs_filtered_all_mods.RData")
mrpc.inf=loadRData(file="C:/Users/Bruin/Documents/GitHub/MRGN_extra/Simulations/GMACvMRGN_sim/simulated_data_all_conf_types/sim_set_3_data/int_and_child_filtered_data/mrpc_5k_small_results_all_confs_filtered_all_mods.RData")
datasets=loadRData(file="C:/Users/Bruin/Documents/GitHub/MRGN_extra/Simulations/GMACvMRGN_sim/simulated_data_all_conf_types/sim_set_3_data/mrgn_v_gmac_v_mrpc_5k_datasets_all_mods_conf_types.RData")
conf.list.mrgn=loadRData(file="C:/Users/Bruin/Documents/GitHub/MRGN_extra/Simulations/GMACvMRGN_sim/simulated_data_all_conf_types/sim_set_3_data/int_and_child_filtered_data/mrgn_5k_conf_list_all_confs_filtered_all_mods.RData")
#conf.list.mrpc = loadRData(file="C:/Users/Bruin/Documents/GitHub/MRGN_extra/Simulations/GMACvMRGN_sim/simulated_data_all_conf_types/sim_set_3_data/int_and_child_filtered_data/mrpc_5k_conf_list_all_confs_filtered_all_mods.RData")
conf.mat = loadRData(file = "C:/Users/Bruin/Documents/GitHub/MRGN_extra/Simulations/GMACvMRGN_sim/simulated_data_all_conf_types/sim_set_3_data/mrgn_v_gmac_v_mrpc_5k_datasets_all_mods_conf_types_conf_mat.RData")
#======================================================================================
#read simulation results for conf selection with no FDR (selected at alpha < 0.01)
conf.list.alpha01 = loadRData('C:/Users/Bruin/Documents/GitHub/MRGN_extra/Simulations/GMACvMRGN_sim/simulated_data_all_conf_types/sim_set_3_data/int_and_child_filtered_data/alpha_01_selected_confs_results/MRGN_15confs_liberal_alpha01_conf_list.RData')
mrgn.inf.alpha01 = loadRData('C:/Users/Bruin/Documents/GitHub/MRGN_extra/Simulations/GMACvMRGN_sim/simulated_data_all_conf_types/sim_set_3_data/int_and_child_filtered_data/alpha_01_selected_confs_results/MRGN_15confs_liberal_alpha01_inference_results.RData')
#======================================================================================
#comp time results
#comp time table::
mrpc.comp.times = loadRData(file = "C:/Users/Bruin/Documents/GitHub/MRGN_extra/Simulations/GMACvMRGN_sim/simulated_data_all_conf_types/sim_set_3_data/diagnostics/mrpc_comp_times_with_filtering.RData")
mrgn.comp.times = loadRData(file = "C:/Users/Bruin/Documents/GitHub/MRGN_extra/Simulations/GMACvMRGN_sim/simulated_data_all_conf_types/sim_set_3_data/diagnostics/mrgn_comp_times_with_filtering.RData")
ct = cbind.data.frame(`Total Time To Compute All 1500 (hrs)` = c(sum(mrpc.comp.times$Time.to.compute.mrpc)/60,
sum(mrgn.comp.times$Time.to.compute.mrgn)/60),
`Average Time To Compute Per Trio (sec)` = c(mean(mrpc.comp.times$Time.to.compute.mrpc)*60,
mean(mrgn.comp.times$Time.to.compute.mrgn)*60))
row.names(ct) = c("MRPC", "MRGN")
kable(ct, caption = "Computation Times for MRGN and MRPC")
write.csv(ct, "C:/Users/Bruin/Documents/GitHub/MRGN_extra/Manuscript/SuppTables/tablescraps/comp.times.MRGN.MRPC.csv", row.names = T)
#extract just the data
datasets_new = lapply(datasets, function(x) x$data)
#==========================================
#-------confounder-selection-scoring-------
#==========================================
gmac.conf.list = apply(gmac.cis$cov.indicator.list, 1, list)
conf.select.scores = calc.css(true.datasets = datasets_new, gmac.confs.list = gmac.conf.list,
mrgn.confs.list = conf.list.mrgn, conf.names = colnames(conf.mat), plot.graphs = T)
conf.select.scores2 = calc.css(true.datasets = datasets_new, gmac.confs.list = gmac.conf.list,
mrgn.confs.list = conf.list.alpha01, conf.names = colnames(conf.mat), plot.graphs = T)
#save(conf.select.scores, file = 'C:/Users/Bruin/Documents/GitHub/MRGN_extra/Manuscript/conf.select.scores.15confs.RData')
# conf.select.scores = calc.css(true.datasets = datasets, gmac.confs.list = gmac.conf.list,
#                               mrgn.confs.list = conf.list.mrpc, conf.names = colnames(conf.mat))
#==========================================
#-----------Class-Based-Metrics------------
#==========================================
#decompose mrgn inference into the inferred class and the adjacency
mrpc.inf2=unlist(lapply(mrpc.inf, function(x) x$model))
mrpc.adj=lapply(mrpc.inf, function(x) x$Adj)
#get the adjacency for MRGN and the truth
mrgn.adj=lapply(mrgn.inf, get.adj.from.class)
mrgn.adj.alpha01 = lapply(mrgn.inf.alpha01, get.adj.from.class)
true.adj=lapply(convert.truth(params$model), get.adj.from.class)
#convert gmac inference into binary variable
gmac.binary = master.table$gmac.infer
gmac.binary[which(gmac.binary != "No.Med")] = "Mediation"
#confusion matrices
#mrgn
x1.1 = table(MRGN = convert.cats(mrgn.inf), TRUTH = convert.truth(params$model))
x1.2 = rbind(x1.1, Total = colSums(x1.1), Recall = round(diag(x1.1)/colSums(x1.1),4))
x1.3 = cbind(x1.2, Total = c(rowSums(x1.2[1:7,]), " "), Precision = c(round(diag(x1.2)/rowSums(x1.2[1:5,]),4), rep(" ", 3)))
#mrgn with alpha 01 sel confs
x12.1 = table(MRGN = convert.cats(mrgn.inf.alpha01), TRUTH = convert.truth(params$model))
x12.2 = rbind(x12.1, Total = colSums(x12.1), Recall = round(diag(x12.1)/colSums(x12.1),4))
x12.3 = cbind(x12.2, Total = c(rowSums(x12.2[1:7,]), " "), Precision = c(round(diag(x12.2)/rowSums(x12.2[1:5,]),4), rep(" ", 3)))
#mrpc
x2.1 = table(MRPC = convert.cats(mrpc.inf2), TRUTH = convert.truth(params$model))
x2.2 = rbind(x2.1, Total = colSums(x2.1), Recall = round(diag(x2.1)/colSums(x2.1),4))
x2.3 = cbind(x2.2, Total = c(rowSums(x2.2[1:7,]), " "), Precision = c(round(diag(x2.2)/rowSums(x2.2[1:5,]),4), rep(" ", 3)))
#combine tables
final.x12 = cbind(`Inference Method` = c(rep(" ", 3), "MRGN",
rep(" ", 8), "MRGN",
rep(" ", 8), "MRPC", rep(" ", 4)),
`Inference Correction` = c(rep(" ", 3), "None: $\\alpha <0.01$",
rep(" ", 8), "None: $\\alpha <0.01$",
rep(" ", 8), "ADDIS", rep(" ", 4)),
`Confounder Selection Correction` = c(rep(" ", 3), "FDR $ < 0.05$",
rep(" ", 8), "None: $\\alpha <0.01$",
rep(" ", 8), "FDR $< 0.05$", rep(" ", 4)),
Description = c(rownames(x1.3), " ", rownames(x12.3), " ", rownames(x2.3)),
rbind.data.frame(x1.3, rep(" ", 8), x12.3,rep(" ", 8), x2.3))
#print final table
kable(final.x12, row.names = F, caption = "Confusion matrix showing the class-based performance of MRGN and MRPC both methods use the GMAC confounder selection procedure with filtering", escape = FALSE,
booktabs = T)%>%column_spec(1, width = "4em")%>%column_spec(2:3, width = "5em")%>%column_spec(5:11, width = "3em")
write.csv(final.x12, "C:/Users/Bruin/Documents/GitHub/MRGN_extra/Manuscript/SuppTables/tablescraps/Results.15.confs.MRGN.MRPC.class-based.csv", row.names = F)
#==========================================
#-----------Edge-Based-Metrics------------
#==========================================
# get the mean edge based metrics for each trio
edge.metrics.mrgn=as.data.frame(matrix(0, nrow = 1500, ncol = 4))
colnames(edge.metrics.mrgn)=c("prec_edge", "recall","EW_prec_edge", "EW_recall")
edge.metrics.mrgn.alpha01=as.data.frame(matrix(0, nrow = 1500, ncol = 4))
colnames(edge.metrics.mrgn.alpha01)=c("prec_edge", "recall","EW_prec_edge", "EW_recall")
edge.metrics.mrpc=as.data.frame(matrix(0, nrow = 1500, ncol = 4))
colnames(edge.metrics.mrpc)=c("prec_edge", "recall","EW_prec_edge", "EW_recall")
for(i in 1:1500){
edge.metrics.mrgn[i,] = c(get.metrics(Truth = convert.truth(params$model)[i],
Inferred = mrgn.adj[[i]],
get.adj.truth = TRUE),
get.metrics(Truth = convert.truth(params$model)[i],
Inferred = mrgn.adj[[i]],
get.adj.truth = TRUE,
weight.edge.directed.present = 1,
weight.edge.present.only = 1))
edge.metrics.mrgn.alpha01[i,] = c(get.metrics(Truth = convert.truth(params$model)[i],
Inferred = mrgn.adj.alpha01[[i]],
get.adj.truth = TRUE),
get.metrics(Truth = convert.truth(params$model)[i],
Inferred = mrgn.adj.alpha01[[i]],
get.adj.truth = TRUE,
weight.edge.directed.present = 1,
weight.edge.present.only = 1))
edge.metrics.mrpc[i,] = c(get.metrics(Truth = convert.truth(params$model)[i],
Inferred = mrpc.adj[[i]],
get.adj.truth = TRUE),
get.metrics(Truth = convert.truth(params$model)[i],
Inferred = mrgn.adj[[i]],
get.adj.truth = TRUE,
weight.edge.directed.present = 1,
weight.edge.present.only = 1))
}
#==========================================
#-----------Class-Based-Metrics------------
#==========================================
#decompose mrgn inference into the inferred class and the adjacency
mrpc.inf2=unlist(lapply(mrpc.inf, function(x) x$model))
mrpc.adj=lapply(mrpc.inf, function(x) x$Adj)
#get the adjacency for MRGN and the truth
mrgn.adj=lapply(mrgn.inf, get.adj.from.class)
mrgn.adj.alpha01 = lapply(mrgn.inf.alpha01, get.adj.from.class)
true.adj=lapply(convert.truth(params$model), get.adj.from.class)
#convert gmac inference into binary variable
gmac.binary = master.table$gmac.infer
gmac.binary[which(gmac.binary != "No.Med")] = "Mediation"
#confusion matrices
#mrgn
x1.1 = table(MRGN = convert.cats(mrgn.inf), TRUTH = convert.truth(params$model))
x1.2 = rbind(x1.1, Total = colSums(x1.1), Recall = round(diag(x1.1)/colSums(x1.1),4))
x1.3 = cbind(x1.2, Total = c(rowSums(x1.2[1:7,]), " "), Precision = c(round(diag(x1.2)/rowSums(x1.2[1:5,]),4), rep(" ", 3)))
#mrgn with alpha 01 sel confs
x12.1 = table(MRGN = convert.cats(mrgn.inf.alpha01), TRUTH = convert.truth(params$model))
x12.2 = rbind(x12.1, Total = colSums(x12.1), Recall = round(diag(x12.1)/colSums(x12.1),4))
x12.3 = cbind(x12.2, Total = c(rowSums(x12.2[1:7,]), " "), Precision = c(round(diag(x12.2)/rowSums(x12.2[1:5,]),4), rep(" ", 3)))
#mrpc
x2.1 = table(MRPC = convert.cats(mrpc.inf2), TRUTH = convert.truth(params$model))
x2.2 = rbind(x2.1, Total = colSums(x2.1), Recall = round(diag(x2.1)/colSums(x2.1),4))
x2.3 = cbind(x2.2, Total = c(rowSums(x2.2[1:7,]), " "), Precision = c(round(diag(x2.2)/rowSums(x2.2[1:5,]),4), rep(" ", 3)))
#combine tables
final.x12 = cbind(`Inference Method` = c(rep(" ", 3), "MRGN",
rep(" ", 8), "MRGN",
rep(" ", 8), "MRPC", rep(" ", 4)),
`Inference Correction` = c(rep(" ", 3), "None: $\\alpha <0.01$",
rep(" ", 8), "None: $\\alpha <0.01$",
rep(" ", 8), "ADDIS", rep(" ", 4)),
`Confounder Selection Correction` = c(rep(" ", 3), "FDR $ < 0.05$",
rep(" ", 8), "None: $\\alpha <0.01$",
rep(" ", 8), "FDR $< 0.05$", rep(" ", 4)),
Description = c(rownames(x1.3), " ", rownames(x12.3), " ", rownames(x2.3)),
rbind.data.frame(x1.3, rep(" ", 8), x12.3,rep(" ", 8), x2.3))
#print final table
kable(final.x12, row.names = F, caption = "Confusion matrix showing the class-based performance of MRGN and MRPC both methods use the GMAC confounder selection procedure with filtering", escape = FALSE,
booktabs = T)%>%column_spec(1, width = "4em")%>%column_spec(2:3, width = "5em")%>%column_spec(5:11, width = "3em")
write.csv(final.x12, "C:/Users/Bruin/Documents/GitHub/MRGN_extra/Manuscript/SuppTables/tablescraps/Results.15.confs.MRGN.MRPC.class-based.csv", row.names = F)
#==========================================
#-----------Edge-Based-Metrics------------
#==========================================
# get the mean edge based metrics for each trio
edge.metrics.mrgn=as.data.frame(matrix(0, nrow = 1500, ncol = 4))
colnames(edge.metrics.mrgn)=c("prec_edge", "recall","EW_prec_edge", "EW_recall")
edge.metrics.mrgn.alpha01=as.data.frame(matrix(0, nrow = 1500, ncol = 4))
colnames(edge.metrics.mrgn.alpha01)=c("prec_edge", "recall","EW_prec_edge", "EW_recall")
edge.metrics.mrpc=as.data.frame(matrix(0, nrow = 1500, ncol = 4))
colnames(edge.metrics.mrpc)=c("prec_edge", "recall","EW_prec_edge", "EW_recall")
for(i in 1:1500){
edge.metrics.mrgn[i,] = c(get.metrics(Truth = convert.truth(params$model)[i],
Inferred = mrgn.adj[[i]],
get.adj.truth = TRUE),
get.metrics(Truth = convert.truth(params$model)[i],
Inferred = mrgn.adj[[i]],
get.adj.truth = TRUE,
weight.edge.directed.present = 1,
weight.edge.present.only = 1))
edge.metrics.mrgn.alpha01[i,] = c(get.metrics(Truth = convert.truth(params$model)[i],
Inferred = mrgn.adj.alpha01[[i]],
get.adj.truth = TRUE),
get.metrics(Truth = convert.truth(params$model)[i],
Inferred = mrgn.adj.alpha01[[i]],
get.adj.truth = TRUE,
weight.edge.directed.present = 1,
weight.edge.present.only = 1))
edge.metrics.mrpc[i,] = c(get.metrics(Truth = convert.truth(params$model)[i],
Inferred = mrpc.adj[[i]],
get.adj.truth = TRUE),
get.metrics(Truth = convert.truth(params$model)[i],
Inferred = mrgn.adj[[i]],
get.adj.truth = TRUE,
weight.edge.directed.present = 1,
weight.edge.present.only = 1))
}
?get.metrics
