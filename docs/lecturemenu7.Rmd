---
title: "Week 7 Notes"
author: "STAT 251 Section 03"
output:
  html_document: default
  #pdf_document: default
always_allow_html: true
header-includes:
  \usepackage{float}
  \usepackage{tikz}

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
library(kableExtra)
library(ggplot2)
library(ggthemes)
library(ggpubr)
library(latex2exp)
library(gganimate)

path = 'C:/Users/Bruin/Documents/GitHub/UI_STAT251-03_Spring_2024/docs/Data/'
```

# Lecture 15Monday, Feb.26th 2024

Now that we have a strong understanding of the theory of mathematical probability we can use it to connect back to estimation and statistical inference. At this point we have learned about three different probability distributions:

* The **population distribution** is the probability distribution of a single observation of a random variable
  * Its properties are described by unknown parameters such as $p$, $\mu$, $\sigma^2$, $\sigma$


* The **data distribution** is the probability distribution of the observations in a sample. 
  * Its properties are described by statistics such as $\bar{x}$ or $\hat{p}$, $s^2$, $s$. 


* The **sampling distribution** is the probability distribution of a statistic that is computed from the observations in a sample. This distribution arises from repeated sampling from the same population with the same sample size and computing statistics from those samples. It tells us how close a given estimate is to the true population parameter it is estimating (sampling error). 

### The Central Limit Theorem

A statistic computed from a random sample or randomized experiment is a random variable whose probability distribution is given by the sampling distribution. One of the most famous results from probability theory says that the distribution of a the mean $\bar{x}$ of a random variable computed from a sample of size $n$ will be approximately normally distributed for large $n$. This result is referred to as the **Central Limit Theorem (CLT)**. Formally the CLT states that for a set of independent and identically distributed random variables $X_1, X_2, ... X_n$, 

\[\frac{\sqrt{n}(\bar{X} - \mu)}{\sigma} \xrightarrow{d} N(0,1)\]

Where $\xrightarrow{d}$ means "converge in distribution" and $\bar{X} = \frac{1}{n} \sum_i X_i$. 


* Each random variable $X_i$ can be thought of as an observation in a sample from the population distribution $X$. 
* Note that the CLT assumes that each $X_i$ comes from the same distribution, and that they all have finite variance. 

Informally, this means that as the sample size increases the shape of a sampling distribution of $\bar{x}$ or $\hat{p}$ will “approach” that of a normal distribution - regardless of the distribution of data distribution of the sample. Therefore the sampling distributions of both $\bar{x}$ and $\hat{p}$ are approximately normal-shaped for moderate to large sample sizes $n$. 


```{r, eval = F, echo=F, warning=F, message=F, fig.height=6, fig.width=10}

#Sampling Distribution of the Proportion
n=c(2, 3, 5, 8, 10,20,40, 80, 100, 200)
resamples = 10000
p = 0.5
sample.size = 100
df.list = list()
for(j in 1:length(n)){
  props = NULL
  for(i in 1:resamples){
    X=rbinom(n[j], 1, prob = p)
    
    props[i]=sum(X/n[j])
  }
  df = cbind.data.frame(sample.size = rep(n[j], resamples), props = props)
  df.list[[j]] = df
}

options(repr.plot.width = 5, repr.plot.height =6)
data.final = do.call('rbind.data.frame', df.list)
#xn = sort(rnorm(10000, n[j]*p, sqrt(n[j]*p*(1-p))))
#yn = dnorm(xn, mean = n[j]*p, sqrt(n[j]*p*(1-p)))

#df = cbind.data.frame(ix = c(1:length(props)), props = props)
#jpeg(paste0('C:/Users/Bruin/Desktop/GS Academia/TA/Teaching STAT 251/FALL/Week_5/CLTpics/',"SS_",i,".jpg"))
ggplot(data = data.final, aes(x = props))+geom_histogram(aes(y = ..density..), 
                                                   #bins = ceiling(sqrt(n[j])),
                                                   #bins = 15,
                                                   binwidth = function(x) 2 * IQR(x) / (length(x)^(1/3)),
                                                   color = 'black',
                                                   fill = 'lightblue')+
  geom_density()+
  theme_hc()+
  xlab(TeX("$\\hat{p}"))+
  ylab("Probability Density")+
  theme(axis.text = element_text(size = 12),
        axis.title = element_text(size = 14))+
  ggtitle('Sampling Distribution of the Proportion')+
  labs(subtitle = 'n =  {closest_state}')+
  transition_states(sample.size, state_length = 3, transition_length = 3)
# jpeg(paste0('C:/Users/Bruin/Desktop/GS Academia/TA/Teaching STAT 251/FALL/Week_5/CLTpics/',"SS_",n[j],".jpg"))
# plot(A)
# dev.off()
anim_save(paste0('C:/Users/Bruin/Documents/GitHub/UI_STAT251-03_Spring_2024/docs/misc/CLT.gif'))

```





```{r, eval = F, echo=F, warning=F, message=F, fig.height=6, fig.width=10}
#Sampling Distribution of the Mean
n=c(2, 3, 5, 8, 10,20,40, 80, 100, 200)
resamples = 10000
p = 0.5
#sample.size = 100
df.list = list()
for(j in 1:length(n)){
  props = NULL
  for(i in 1:resamples){
    X=sample(c(1:6), n[j], replace = TRUE)
    
    props[i]=mean(X)
  }
  df = cbind.data.frame(sample.size = rep(n[j], resamples), props = props)
  df.list[[j]] = df
}

options(repr.plot.width = 5, repr.plot.height =6)
data.final = do.call('rbind.data.frame', df.list)
#xn = sort(rnorm(10000, n[j]*p, sqrt(n[j]*p*(1-p))))
#yn = dnorm(xn, mean = n[j]*p, sqrt(n[j]*p*(1-p)))

#df = cbind.data.frame(ix = c(1:length(props)), props = props)
#jpeg(paste0('C:/Users/Bruin/Desktop/GS Academia/TA/Teaching STAT 251/FALL/Week_5/CLTpics/',"SS_",i,".jpg"))
ggplot(data = data.final, aes(x = props))+geom_histogram(aes(y = ..density..), 
                                                         #bins = ceiling(sqrt(n[j])),
                                                         #bins = 15,
                                                         binwidth = function(x) 2 * IQR(x) / (length(x)^(1/3)),
                                                         color = 'black',
                                                         fill = 'lightblue')+
  geom_density()+
  theme_hc()+
  xlab(TeX("$\\bar{x}"))+
  ylab("Probability Density")+
  theme(axis.text = element_text(size = 12),
        axis.title = element_text(size = 14))+
  ggtitle('Sampling Distribution of the Mean')+
  labs(subtitle = 'n =  {closest_state}')+
  transition_states(sample.size, state_length = 3, transition_length = 3)
# jpeg(paste0('C:/Users/Bruin/Desktop/GS Academia/TA/Teaching STAT 251/FALL/Week_5/CLTpics/',"SS_",n[j],".jpg"))
# plot(A)
# dev.off()
anim_save('C:/Users/Bruin/Documents/GitHub/UI_STAT251-03_Spring_2024/docs/Data/CLT_mean.gif')



#ggarrange(A, B, nrow = 1, ncol = 2)



```


Using the central limit theorem, the distributions for the the sample mean and sample proportion are both approximately normal for large samples

The sampling distribution of the sample proportion $\hat{p}$ has mean $p$ and variance $\frac{p(1-p)}{n}$.

\[\hat{p} \sim N\left(p, \sqrt{\frac{p(1-p)}{n}}\right) \]

The sampling distribution of the sample mean $\bar{x}$ has mean $\mu$ and variance $\frac{\sigma^2}{n}$

\[\bar{x} \sim N\left(\mu, \frac{\sigma}{\sqrt{n}}\right) \]

We can use the CLT to compute the probability of a given value of a statistic. Consider the following example: A scientist studying alligator morphology, plans to sample 50 female American alligators to estimate their mean length. Suppose that the population mean is 8.3 feet with a standard deviation of  1.1 feet. What is the probability she observes a sample mean less than $5.4 feet$? We can apply the CLT to find this probability by simple finding $P(X\leq 5.4)$ where $X\sim N(8.3, \frac{1.1}{\sqrt{50}})$. First, we must convert to a $z$-score:

\[ Z = \frac{\bar{X} - \mu }{\sigma/\sqrt{n} } = \frac{5.4 - 8.3}{1.1/\sqrt{50}} = \frac{-2.9}{0.15} = -19.33\]

\[ P( Z < -19.33) \approx 0\]

Thus it is highly unlikely that the scientist would observe a mean length this short. 
































