---
title: "Week 9 Notes"
author: "STAT 251 Section 03"
output:
  html_document: default
  #pdf_document: default
always_allow_html: true
header-includes:
  \usepackage{float}
  \usepackage{tikz}

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
library(kableExtra)
library(ggplot2)
library(ggthemes)
library(ggpubr)
library(latex2exp)
library(gganimate)

path = 'C:/Users/Bruin/Documents/GitHub/UI_STAT251-03_Spring_2024/docs/Data/'
```

# Lecture 18 Monday, March 4th 2024

Last week we introduced the **confidence interval** which is used to estimate a parameter with an interval of values. We can choose how wide to make the confidence interval by selecting the **confidence level** - which is the probability that the interval will contain the true parameter value **<u>before</u>** the data are gathered. The confidence level is controlled via the standard score $z$. The standard score gives the number of standard errors to add and subtract from our estimate. Therefore, we must look up the appropriate standard score $z$ from the standard normal table.

From last week we saw that for a $95\%$ confidence interval, we must add and subtract approximately $z=2$ standard errors from our estimate $\bar{x}$ or $\hat{p}$. $z$ is sometimes referred to as the **critical value**. The critical value denotes the upper and lower bounds of the confidence interval. In general, if we wish to compute the $(1-\alpha)\%$ confidence interval for the statistics $\bar{x}$ or $\hat{p}$, then we must add and subtract $z_{1-\alpha/2}$ standard errors. The quantity $\alpha/2$ denotes the area that is divided among the two tails of the standard normal distribution. For example, for a $95\%$ confidence interval $\alpha = 0.05$ and $\alpha/2 = 0.025$. 

For example, for a $90\%$ confidence $\alpha = 0.1$, and the corresponding critical value is $z_{1-0.1/2} = z_{0.95}$ which is the 95th percentile from the standard normal distribution. The table below gives several confidence levels, the corresponding values of $\alpha$ and critical values. 

```{r, echo=F, message=F, warning=F}
alpha = c(0.2, 0.15, 0.1, 0.05, 0.01)
df = cbind.data.frame(`Confidence Level` = paste0('$', 100*(1-alpha), '\\%$'),
                      `$\\alpha$` = alpha,
                      `critical value: $z_{1-\\alpha/2}$` = qnorm(1-alpha/2))
                      

kable(df, format = 'html', digits = 2, row.names = F, booktabs = T, escape = F)%>%
  kable_classic(full_width = F, html_font = "Cambria")%>%kable_styling(bootstrap_options = 'striped')

```

* Try it out: give the confidence level and critical value for the $(1-\alpha)\%$ confidence intervals with $\alpha = 0.25$, $\alpha = 0.08$, and $\alpha = 0.03$. 

### An alternative confidence interval for a population mean.

Recall the confidence interval that we introduced for estimating the population mean:

\[ \bar{x} \pm z\frac{\sigma}{\sqrt{n}} \]

The confidence interval above is based on the assumption that the population standard deviation $\sigma$ is known. When $\sigma$ is known the sampling distribution of the $\bar{x}$ is approximately $N(\mu, \sigma/\sqrt{n})$. However, we rarely know the value of $\sigma$ so we must approximate its value with the sample standard deviation $s$ to get 

\[ \bar{x} \pm z\frac{s}{\sqrt{n}} \]

Unfortunately, the confidence level of the confidence interval above will tend to be less than specified. As a result, more confidence intervals will fail to cover the true parameter value than expected. 

* Consider the following example: A social scientist is conducting a study to investigate the average time spent daily on social media by college students. Each week the scientists surveys five college students and asks them to report their time spent on social media. For each sample, the scientist computes the $95\%$ confidence interval for the mean time the students spent on social media. They repeat this process 100 times. Suppose the population mean time spent on social media is $\mu = 120$ minutes with a standard deviation of $\sigma = 10$ minutes. The plot below shows 100 confidence intervals computed using $\bar{x} \pm z\frac{s}{\sqrt{n}}$ where each CI is computed from a sample of $5$ observations from $N(120, 10)$:

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.height=6, fig.width=10, fig.cap="**Figure**: Each point represents the sample mean from a hypothetical sample of 5 college students. The whiskers extending from each point give the coverage of the confidence interval computed for each sample. The black dotted line gives the value of hypothetical population mean time spent on social media. The CI's highlighted in red represent those that fail to capture the population mean"}

set.seed(123)
mu = 120
sigma = 10
n = 5
z = 1.96
repeats = 100
samples = lapply(c(1:repeats), function(x) rnorm(n, mean = mu, sd = sigma))

means.vec = unlist(lapply(samples, function(x) mean(x)))
se.vec = unlist(lapply(samples, function(x) sd(x)/sqrt(n)))

xpos = 1:100
ymin = means.vec-2*se.vec
ymax = means.vec+2*se.vec

ix = which(mu < ymin | mu > ymax)

ind = rep('True', 100)
ind[ix] = 'False'

df = cbind.data.frame(`$\\bar{x}$` = means.vec,
                      `$SE$` = se.vec,
                      xpos = xpos,
                      `Covers Parameter` = ind)

ggplot(data = df, aes(x = xpos, y = `$\\bar{x}$`, color = `Covers Parameter`))+
  geom_hline(yintercept = mu, linetype = 'dashed', linewidth = 2, color = 'black')+
  geom_point(size = 3)+
  geom_errorbar(aes(ymin = ymin, ymax = ymax), height = 0.01, linewidth = 1)+
  geom_text(aes(x = -0.1, y = mu+0.1), label = TeX('$\\mu$'), size = 6, color = 'black')+
  theme_classic2()+
  scale_x_continuous(breaks = seq(1, 100, 5))+
  xlab('Sample number')+
  ylab(TeX('$\\bar{x}$'))+
  theme(legend.position = 'top',
        legend.text = element_text(size = 12),
        axis.title = element_text(size = 16),
        axis.text = element_text(size = 12))


```

Based on the plot and example above, the actual proportion of confidence intervals that fail to capture the population mean is $12\%$, which is much higher than the expected frequency of only $5\%$. This occurs because the sampling distribution of $\bar{x}$ no longer follows a normal distribution. When we substitute $s/\sqrt{n}$ for $\sigma/\sqrt{n}$ the sampling distribution of $\bar{x}$ changes to a distribution called the **$t$-distribution**. 

Like the normal distribution, the $t$ distribution is a bell curve but it has "heavier tails" - that is to say, it has more probability density in the tails of the distribution. 

```{r, echo=FALSE, message=FALSE, warning=FALSE, error=FALSE, results = 'hide', fig.height=6, fig.width=10}

x = seq(-3, 3, length=1000)
hx = dnorm(x)

degf = c(1, 2, 5, 10)
colors = c("red", "blue", "darkgreen", "darkgoldenrod1", "black")
labels = c("df = 1", "df = 2", "df = 5", "df = 10", "standard normal")
plot(x, hx, type="l", lty=1, xlab="x value", lwd = 3,
     ylab="Density", main="Comparison of t Distributions")

#The relevant modification
mapply(function(DoF, W, C) lines(x, dt(x, DoF), lwd=W, col=C), DoF = degf, W = c(3,3,3,3), C = colors[-5])

legend("topleft", inset=.05, title="t Distributions",
       labels, lwd=2, lty=c(1, 1, 1, 1, 1), col=colors)
```

The amount of probability density in the tails of a $t$ distribution is controlled by the **degrees of freedom** of the distribution. The confidence interval for $\mu$ that uses $s/\sqrt{n}$ instead of $\sigma/\sqrt{n}$ is given by

\[ \bar{x} \pm t\frac{s}{\sqrt{n}} \]

The quantity $t$ is called the $t$-score and is the $1-\alpha/2$ percentile of $t$-distribution with $n-1$ degrees of freedom denoted $t(n-1)$. Like the standard score $z$, we must look up the $t$-score corresponding to the desired confidence level from a $t$-distribution table:


```{r, echo=F, message=F, warning=F}
DF = c(1:30, 40, 50, 100)
probs = rbind.data.frame(cbind.data.frame(c('$DF$', DF), 
                         c('',round(qt(1-0.5/2, DF), 3)), c('',round(qt(1-0.4/2, DF),3)),
                         c('',round(qt(1-0.3/2, DF),3)), c('',round(qt(1-0.25/2, DF),3)), 
                         c('',round(qt(1-0.2/2, DF), 3)), c('',round(qt(1-0.15/2, DF),3)), 
                         c('',round(qt(1-0.1/2, DF),3)), c('',round(qt(1-0.05/2, DF),3)),
                         c('',round(qt(1-0.01/2, DF),3)), c('',round(qt(1 - 0.005/2, DF),3)),
                         c('',round(qt(1 - 0.001/2, DF),3))),
                         c('Z-score', round(qnorm(1-c(0.5, 0.4, 0.3, 0.25, 0.2, 0.15, 0.1, 0.05, 0.01, 0.005, 0.001)/2),3)),
                         c('Confidence Level:', 
                           paste0('$',100*(1-c(0.5, 0.4, 0.3, 0.25, 0.2, 0.15, 0.1, 0.05, 0.01, 0.005, 0.001)), '\\%$')))
                        

df = rbind.data.frame(c('Two tail', 0.5, 0.4, 0.3, 0.25, 0.2, 0.15, 0.1, 0.05, 0.01, 0.005, 0.001), probs)

kable(df, format = 'html', digits = 2, col.names = c('Upper tail', 0.25, 0.2, 0.15, 0.125, 0.1, 0.075, 0.05, 0.025, 0.005, 0.0025, 0.0005),
      row.names = F, booktabs = F, escape = F)%>%
  kable_classic(full_width = F, html_font = "Cambria")%>%kable_styling(bootstrap_options = 'striped')

```

The table for the $t$ distribution is organized a little bit differently than the one we've seen previously for the standard normal distribution. The right-most column gives the degrees of freedom, columns give the different upper tail and two tail probabilities, and the values in the middle of the table are the $t$ scores that correspond to those probabilities. 

Use the table above to verify that the following $t$-scores corresponding to each confidence level and sample size are correct.

```{r, echo=F, message=F, warning=F}
alpha = c(0.1, 0.15, 0.05, 0.01, 0.2)
n = c(3, 5, 10, 14, 22)
df = cbind.data.frame(`Confidence Level` = paste0('$', 100*(1-alpha), '\\%$'),
                      `Sample size` = paste0('$n = ', n, '$'),
                      `$\\alpha$` = alpha,
                      `critical value: $t_{1-\\alpha/2}$` = round(qt(1-alpha/2, df = n), 3))
                      

kable(df, format = 'html', digits = 2, row.names = F, booktabs = T, escape = F)%>%
  kable_classic(full_width = F, html_font = "Cambria")%>%kable_styling(bootstrap_options = 'striped')

```


One nice property of the $t$-distribution is that it converges to the standard normal distribution as $n$ goes to infinity. Stated another way, a $t$-distribution with $\infty$ degrees of freedom is exactly the standard normal distribution. This means that with large enough sample size, both the confidence interval based on the standard normal distribution and the one bases on the $t$ distribution should yield nearly identical results. In fact, for $n \geq 30$ the difference between the standard normal distribution and $t$-distribution is nearly indistinguishable.

