---
title: "Week 14 Notes"
author: "STAT 251 Section 03"
output:
  html_document: default
  #pdf_document: default
always_allow_html: true
header-includes:
  \usepackage{float}
  \usepackage{tikz}
bibliography: C:/Users/Bruin/Documents/GitHub/UI_STAT251-03_Spring_2024/docs/misc/Week_13_bibs.bib
urlcolor: blue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
library(kableExtra)
library(ggplot2)
library(ggthemes)
library(ggpubr)
library(latex2exp)
library(gganimate)

path = 'C:/Users/Bruin/Documents/GitHub/UI_STAT251-03_Spring_2024/docs/Data/'

##stat pack
source('C:/Users/Bruin/Documents/GitHub/UI_STAT251-03_Spring_2024/docs/misc/stat251_tools.R')

```

# Lecture 26 Monday, April 8th 2024
  
### Comparing two means

Last week we learned how to compare two populations across a qualitative response variable by comparing their relative proportions. Now we will learn how we can compare two groups on a quantitative response variable by comparing their means. There are many cases where researchers might be interesting comparing groups across a quantitative variable. For example, a teacher may be interested in comparing the average test scores of students in two different classes (Class A and Class B). A social scientist may be interest in whether there is a difference in salaries between men and women within a company. In any case, we are again dealing with two samples of sizes $n_1$ and $n_2$ which come from populations <i>population 1</i> and <i>population 2</i> and with means as $\mu_1$ and $\mu_2$. 

```{r, echo=FALSE, warning=F, message=F}
set.seed(123)

df = cbind.data.frame(Population = c(1, 2),
                      `Population Mean` = c('$\\mu_1$', '$\\mu_2$'),
                      `Population Stdev` = c('$\\sigma_1$','$\\sigma_2$'),
                      `Sample Size` = c('$n_1$', '$n_2$'),
                      `Sample Mean` = c('$\\bar{x}_1$', '$\\bar{x}_2$'),
                      `Sample Stdev` = c('$s_1$','$s_2$'))

kable(df, format = 'html', digits = 2,
      row.names = F, booktabs = T, escape = F)%>%
  kable_classic(full_width = F, html_font = "Cambria")%>%kable_styling(bootstrap_options = 'striped')



```


Let $\mu_d = \mu_1 - \mu_2$ be the mean difference between the two populations. We can construct confidence intervals to estimate the average difference as well as conduct hypothesis tests to determine if two populations are significantly different.

### A confidence interval for the mean difference $\mu_d$

We will begin by assuming that we are dealing with two independent samples from two distinct populations. The natural estimator of $\mu_d$ is the difference between the sample means 

\[\hat{\mu}_d = \bar{x}_1 - \bar{x}_2\]

To base our inference on the above estimator, we must know its sampling distribution. If we assume that both samples come from populations that are normally distributed, then the distribution of the difference will also be normally distributed and the variances will add:

\[Var[\mu_1 - \mu_2] = \frac{\sigma_1^2}{n_1}+\frac{\sigma_2^2}{n_2}\]

In practice, $\sigma_1^2$ and $\sigma_2^2$ are unknown population parameters but can be estimated by substituting in the sample variances $s_1^2$ and $s_2^2$. This gives the following standard deviation for the estimator $\hat{\mu}_d$

\[SE(\hat{\mu}_d) = \sqrt{\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2}}  \]

Just as it was for a single mean, estimating the population variances with the sample variances adds additional uncertainty. Thus, the the sampling distribution for the difference in two means is $t$-distributed, although the degrees of freedom are calculated differently. The actual formula for the degrees of freedom is quite messy and difficult to compute:

\[df = \frac{\left(\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2}\right)^2}{ \frac{1}{n_1 - 1}\left(\frac{s_1^2}{n_1}\right)^2 + \frac{1}{n_2-1}\left(\frac{s_2^2}{n_2}\right)^2} \]

We will instead compute the degrees of freedom by taking the smaller of $n_1-1$ and $n_2 - 1$ which is a lower bound on the formula above 

\[\hat{\mu}_d \sim t(\min(n_1 - 1, n_2 - 1)) \]

The margin of error for estimating the mean difference at the $(1-\alpha)\%$ level is given by

\[m = t_{1-\alpha/2} \times SE(\hat{\mu}_d) \]

which gives the following confidence interval for the mean difference

\[(\bar{x}_1 - \bar{x}_2) \pm  t_{1-\alpha/2} \times SE(\hat{\mu}_d)\]

**Example: Comparing Customer Satisfaction Levels** - Suppose we want to compare the customer satisfaction levels of two competing cable television companies, Company 1 and Company 2. We randomly select customers from each company and ask them to rate their cable companies on a five-point scale (with 1 being least satisfied and 5 most satisfied). The data are summarized in the table below:


```{r, echo=FALSE, warning=F, message=F}
set.seed(123)

df = cbind.data.frame(`Group` = c('Company 1', 'Company 2'),
                      `Number of customers` = c(174, 355),
                      `Sample Mean Rating` = c(4.2, 3.8),
                      `Sample Stdev` = c(0.8, 1.1))

kable(df, format = 'html', digits = 2,
      row.names = F, booktabs = T, escape = F)%>%
  kable_classic(full_width = F, html_font = "Cambria")%>%kable_styling(bootstrap_options = 'striped')



```


Estimate the difference in mean satisfaction levels between the two companies at the $95\%$ confidence level.

Let $\mu_1$ represent the mean satisfaction score for company 1 and $\mu_2$ represent the mean satisfaction score for company 2. The estimated mean difference in customer satisfaction is 
\[\hat{\mu_d} = 4.2 - 3.8 = 0.4 \]

Since the confidence level is $95\%$ the standard score will be approximately the $t_{1-0.05/2} = t_{0.975}$ or the $97.5th$ percentile of a $t$-distribution with $173$ degrees of freedom. Since the $t$ and $z$ distributions are approximately for sample sizes $\geq 30$ we will use the standard score $1.96$. The standard error of the difference is given by 

\[SE(\hat{\mu}_d) = \sqrt{\frac{0.8^2}{174}+\frac{1.1^2}{355}} =0.0842  \]

Which yields the follow margin of error

\[ m = 1.96 (0.0842) = 0.165\]

The $95\%$ confidence interval is $[0.24, 0.56]$. Thus, at the $95\%$ confidence level we estimate the mean difference in customer satisfaction score to be no less than $0.24$ and no more than $0.56$. Notice that the above confidence interval does not span zero and thus likely constitutes a real, but small, difference between the companies

### A significance test for comparing two means: independent samples

We can also test for a difference between two groups on a quantitative response. variable by comparing their means. The set up for a significance test for a difference in two means is more or less the same as we saw previously for two proportions, however, the calculations now involve $\bar{x}_1$, $\bar{x}_2$, $s_1$ and $s_2$. Recall that, under the assumption of normality for both populations and when using the sample standard deviations to estimate $\sigma_1$ and $\sigma_2$ the difference in means is $t$-distributed. We will see that test statistic $t_{obs}$ is the standardized difference and has approximately the same distribution. Here’s how we set up a two-sample hypothesis test for means:

**1. Assumptions**

  * Data constitute a simple random sample 
  
  * The two groups are independent
  
  * Both populations are normally distributed

**2. Null and Alternative Hypotheses**

  * The **null** hypothesis is generally that the two population means are equal (i.e no difference)
  
  \[H_0: \mu_1 = \mu_2 \ \ \  \text{which is the same as} \ \ \ H_0: \mu_1 - \mu_2 = 0\]
  
  * The alternative hypothesis can be either lower, upper, or two tailed just as it was with our univariate tests. The table below gives the possible alternative hypotheses and their critical values:
  
```{r, echo=FALSE, warning=F, message=F}
set.seed(123)

df = cbind.data.frame(`Alternative Hypothesis` = c('$H_A: \\mu_1 - \\mu_2 \\neq 0$','$H_A: \\mu_1 - \\mu_2 < 0$','$H_A: \\mu_1 - \\mu_2 > 0$'),
                      `Critical Value` = c('$t_{1-\\alpha/2}$','$t_\\alpha$','$t_{1-\\alpha}$'),
                      `Rejection Region` = c('$|t| \\geq t_{1-\\alpha/2}$',
                                             '$t\\leq t_{\\alpha}$',
                                             '$t\\geq t_{1-\\alpha}$'))

kable(df, format = 'html', digits = 2,
      row.names = F, booktabs = T, escape = F)%>%
  kable_classic(full_width = F, html_font = "Cambria")%>%kable_styling(bootstrap_options = 'striped')



```

**3. Test statistic**

  * Under the null hypotheses the test statistic is the standardized difference
  
  \[t_{obs} = \frac{(\bar{x}_1 - \bar{x}_2) - (\mu_1 - \mu_2)}{\sqrt{\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2}}}  \]
  
  The above test statistic is only approximately $t$-distributed. However, the lower bound for the degrees of freedom given by $\min(n_1 - 1, n_2 - 1)$ generally leads to conservative estimates and tests and is thus favorable. 
  

**4. $p$-value**

  * The $p$-values corresponding to each alternative hypothesis are listed in the table below

```{r, echo=FALSE, warning=F, message=F}
set.seed(123)

df = cbind.data.frame(`Alternative Hypothesis` = c('$H_A: \\mu_1 - \\mu_2 \\neq 0$','$H_A: \\mu_1 - \\mu_2 < 0$','$H_A: \\mu_1 - \\mu_2 > 0$'),
                      `$p$-value` = c('$P(|t| \\geq |t_{obs}||H_0)$',
                                             '$P(t \\leq t_{obs}|H_0)$',
                                             '$P(t\\geq t_{obs}|H_0)$'))

kable(df, format = 'html', digits = 2,
      row.names = F, booktabs = T, escape = F)%>%
  kable_classic(full_width = F, html_font = "Cambria")%>%kable_styling(bootstrap_options = 'striped')



```

**5. Decision rule**

  \[\text{Reject} \ \ H_0 \ \ \text{if} \ \ \text{$p$-value} < \alpha \]
  
  

#### The pooled $t$ test

There is one situation where the above test statistic has exactly a $t$-distribution and that occurs when we can assume that both populations have the same standard deviation. In this case, we need only substitute a single sample standard deviation for $\sigma_1$ and $\sigma_2$. We call this the pooled estimate of the standard deviation:

\[ s_{pooled} = \sqrt{ \frac{(n_1 - 1)s_1^2 + (n_2 -1)s_2^2}{n_1+n_2 - 2}}\]

$s_{pooled}$ is called the **pooled estimator** of $\sigma_d$ because it combines the information from both samples. 

The test statistic under the assumption of equal variances becomes 

\[t_{obs} = \frac{(\bar{x}_1 - \bar{x}_2) - (\mu_1 - \mu_2)}{s_{pooled}\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}}  \]

which is exactly distributed as a $t$ distribution with $n_1+n_2 - 2$ degrees of freedom. The test based on the pooled estimate of the standard deviation is more powerful because the sampling distribution is exact and not an approximation as it is in the unpooled case.

Which test should you use?

  * In practice, a significance test for determining equality of variances can be run prior to the $t$-test to determine if the pooled or unpooled test statistic should be used. More information about this test can be found <a href="https://www.itl.nist.gov/div898/handbook/eda/section3/eda359.htm#:~:text=An%20F%2Dtest%20(Snedecor%20and,the%20variances%20are%20not%20equal.">here</a>


**Example: NCAA Womens Basketball** - Sunday April 7th South Carolina and Iowa contended for the NCAA womens basketball championship. Consider the following table which gives the opponent and number of points scored for both teams in their last $15$ games leading up to the championship.

```{r, echo=FALSE, warning=F, message=F}
set.seed(123)

sc.matchup = rev(c('UConn','Tenessee','Georgia','Alabama', 'Kentucky', 'Arkansas', 'Tenessee', 'Texas A&M','Tenessee', 'LSU','Presbyterian', 'UNC', 'Indiana', 'Oregon State','NC State'))
sc = c(78, 70, 79, 88, 91, 79, 74, 79, 76, 98, 103, 72, 70, 66, 83)
spacer = rep('', 15)
io.matchup = rev(c('Penn State','Nebraska','Michigan','Indiana','Illinois','Minnesota', 'Ohio State', 'Penn State', 'Michigan', 'Nebraska', 'Holy Cross', 'West Virginia', 'Colorado', 'LSU', 'UConn'))
io = c(71, 94, 89, 64, 91, 94, 95, 95, 93, 108, 101, 69, 106, 79, 111)

df1 = cbind.data.frame(`South Carolina` = sc,
                       `Matchup` = sc.matchup,
                       `-` = spacer,
                       `Iowa` = io,
                       `Matchup` = io.matchup)

kable(df1, format = 'html', digits = 2,
      row.names = F, booktabs = T, escape = F)%>%
  kable_classic(full_width = F, html_font = "Cambria")%>%kable_styling(bootstrap_options = 'striped')



```


The summary of the last $15$ games is given below:

```{r, echo=FALSE, warning=F, message=F}
set.seed(123)

sc.matchup = rev(c('UConn','Tenessee','Georgia','Alabama', 'Kentucky', 'Arkansas', 'Tenessee', 'Texas A&M','Tenessee', 'LSU','Presbyterian', 'UNC', 'Indiana', 'Oregon State','NC State'))
sc = c(78, 70, 79, 88, 91, 79, 74, 79, 76, 98, 103, 72, 70, 66, 83)
spacer = rep('', 15)
io.matchup = rev(c('Penn State','Nebraska','Michigan','Indiana','Illinois','Minnesota', 'Ohio State', 'Penn State', 'Michigan', 'Nebraska', 'Holy Cross', 'West Virginia', 'Colorado', 'LSU', 'UConn'))
io = c(71, 94, 89, 64, 91, 94, 95, 95, 93, 108, 101, 69, 106, 79, 111)

df = cbind.data.frame(Population = c('Iowa', 'South Carolina'),
                      `Population Mean` = c('$\\mu_1$', '$\\mu_2$'),
                      `Sample Size` = c('$n_1 = 15$', '$n_2 = 15$'),
                      `Sample Mean` = c(round(mean(io), 2), round(mean(sc), 2)),
                      `Sample Stdev` = c(round(sd(io), 2), round(sd(sc), 2)))

kable(df, format = 'html', digits = 2,
      row.names = F, booktabs = T, escape = F)%>%
  kable_classic(full_width = F, html_font = "Cambria")%>%kable_styling(bootstrap_options = 'striped')



```


Conduct a unpooled two sample $t$-test at the $\alpha = 0.05$ significance level to determine if there is a significant difference between the championship teams in the mean number of points scored per game.

  1. Let $\mu_1$ be the mean number of points scored per game for Iowa and $\mu_2$ be the mean number of points score per game for South Carolina. The null hypothesis is that there is no difference in the mean number of points between the two teams 
  
  \[H_0: \mu_1 = \mu_2 \]
  
  The alternative hypothesis is that the two teams are different
  
  \[H_A: \mu_1 \neq \mu_2\]
  
  2. The estimated difference is given by $\hat{\mu}_d = \bar{x}_1 - \bar{x}_2 = 10.27$. The test statistic for the unpooled test is 
  
  \[ t_{obs} = \frac{90.67 - 80.40}{\sqrt{\frac{14.21^2}{15}+\frac{10.57^2}{15}}} \approx 2.246\]
  
  which is approximately distributed as 
  
  \[ t_{obs}\sim t(df = 14) \]
  
  3. The pvalue is 
  
  \[\text{$p$-value} = 2\left[P(|t| \geq |t_{obs}||H_0)\right] = 2(0.0207) = 0.0414 \]
  
  4. Based ont the $p$-value above we would narrowly reject the null hypothesis and conclude that Iowa scores significantly more points per game than South Carolina on average. The outcome of the championship was a 75 - 87 victory for South Carolina. Given the conclusion of our test, this is a testament to South Carolina's defensive prowess in being able to shut down a high scoring team like Iowa. 


# Lecture 27 Monday, April 10th 2024

### Paired $t$ test
We know that comparative methods (i.e methods that compare two groups/samples across a quantitative variable) are more common and often preferred over one sample procedures. One common comparative design that makes use of single-sample procedures for a population mean is called the paired $t$-test. This test is used to draw inferences about a population mean in matched pairs designs and can be thought of as the parametric analogue of the <i>sign test</i> we learned previously. Recall that in matched pairs studies subjects are matched in pairs and the quantitative outcome is compared within each pair. 

  * matched pair designs are most common when randomization is not possible
  
  * used when observations are taken on the same subject (before and after treatment)
  
In a paired $t$-test we convert a comparative study into a one-sample procedure by making the response variable the difference between the two observations in each pair $d_i = x_i - y_i$. The parameter under study is the population mean difference $\mu_d$ which can be estimated by the sample mean difference $\bar{x}_d = \bar{x} - \bar{y}$ computed over all pairwise differences. The standard deviation of the difference $\sigma_d$ is then estimated with the sample standard deviation difference. Inference is then treated in the same way as the confidence interval and significance test procedures for a single sample

  * the $(1 - \alpha)\%$ confidence interval for the mean pairwise difference is 
  
  \[ \bar{x}_d \pm t_{1-\alpha/2} \frac{s_d}{\sqrt{n}}\]
  
  * the test statistic for a signifcance test regargin the pairwise difference is given by
  
  \[t_{obs} = \frac{\bar{x}_d - \mu_d}{s_d/\sqrt{n}} \sim t(n - 1) \]
  
  * by treating the above procedure as a one-sample $t$ test we make the assumption that the population distribution of differences is approximately normal. 
  
**Example: Revisting the Spousal Dominance Problem** - Recall the study comparing the ratings of husbands and wives on the perceived relative influence of each member of the couple on a major financial decision.

```{r, echo=FALSE, warning=F, message=F}
set.seed(123)

Couple = c(1:17)
Husband = c(5,4,6,6,3,2,5,3,1,4,5,4,4,7,5,5,5)
Wife = c(3,3,4,5,3,3,2,3,2,3,2,2,5,2,5,3,1)
Difference = Husband - Wife

df = cbind.data.frame(Couple, Husband, Wife, Difference)

kable(df, format = 'html', digits = 2, 
      row.names = F, booktabs = T, escape = F)%>%
  kable_classic(full_width = F, html_font = "Cambria")%>%kable_styling(bootstrap_options = 'striped')


```

A summary of the difference in rating between husbands and wives is given below:

```{r, echo=FALSE, warning=F, message=F}
set.seed(123)

Couple = c(1:17)
Husband = c(5,4,6,6,3,2,5,3,1,4,5,4,4,7,5,5,5)
Wife = c(3,3,4,5,3,3,2,3,2,3,2,2,5,2,5,3,1)
Difference = Husband - Wife

df = cbind.data.frame(`Parameter` = c('$\\mu_d$'),
                      `Estimate` = c(round(mean(Difference),2)),
                      `Stdev` = c(round(sd(Difference), 2)))

kable(df, format = 'html', digits = 2, 
      row.names = F, booktabs = T, escape = F)%>%
  kable_classic(full_width = F, html_font = "Cambria")%>%kable_styling(bootstrap_options = 'striped')


```

Conduct a paired $t$-test at the $\alpha = 0.05$ significance level to determine if husbands and wives differ in their percieved influence on financial decision making

### Statistical Inference for qualitative data

The table below summarizes the procedures we have learned so far in the course

```{r, echo=F, message=F, warning=F}

df = cbind.data.frame(`Parameter` = c('$p$','$p_1 - p_2$', '$\\mu$', '$\\mu_1 - \\mu_2$','$\\mu_1 - \\mu_2$', '$\\mu_d$'),
                      `Type` = c('one-sample', 'two-sample', 'one-sample', 'two-sample', 'pooled two-sample', 'matched pairs'),
                      `Response Variable` = c('Categorical','Categorical', 'Quantatitive', 'Quantitative', 'Quantitative','Quantitative'),
                      
                      `$(1 - \\alpha)\\%$ CI` = c('$\\hat{p}\\pm Z_{1-\\alpha/2}\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}$',
                                                  
                                                  '$(\\hat{p}_1 - \\hat{p}_2)\\pm Z_{1-\\alpha/2} \\sqrt{\\frac{\\hat{p}_1(1-\\hat{p}_1)}{n_1}+\\frac{\\hat{p}_2(1-\\hat{p}_2)}{n_2}}$',
                                                  
                                                  '$\\bar{x} \\pm t_{1-\\alpha/2, n-1}\\frac{s}{\\sqrt{n}}$',
                                                  
                                                  '$(\\bar{x}_1 - \\bar{x}_2) \\pm  t_{1-\\alpha/2, \\min(n_1 -1, n_2-1)} \\sqrt{\\frac{s_1^2}{n_1}+\\frac{s_2^2}{n_2}}$',
                                                  
                                                  '$(\\bar{x}_1 - \\bar{x}_2) \\pm  t_{1-\\alpha/2, \\min(n_1 -1, n_2-1)} s_{pooled}\\sqrt{\\frac{1}{n_1}+\\frac{1}{n_2}}$',
                                                  
                                                  '$\\bar{x}_d \\pm t_{1-\\alpha/2, n-1}\\frac{s_d}{\\sqrt{n}}$'),
                      
                      
                      `Test statistic` = c('$\\frac{\\hat{p} - p_0}{\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}}$',
                                           
                                           '$\\frac{\\hat{p}_1 - \\hat{p}_2}{ \\sqrt{\\hat{p}(1-\\hat{p})\\left(\\frac{1}{n_1}+\\frac{1}{n_2}\\right)}}$',
                                           
                                           '$\\frac{\\bar{x} - \\mu_0}{s/\\sqrt{n}}$',
                                           
                                           '$\\frac{\\bar{x}_1 - \\bar{x}_2}{\\sqrt{\\frac{s_1^2}{n_1}+\\frac{s_2^2}{n_2}}}$',
                                           
                                           '$\\frac{\\bar{x}_1 - \\bar{x}_2}{s_{pooled}\\sqrt{\\frac{1}{n_1}+\\frac{1}{n_2}}}$',
                                           '$\\frac{\\bar{x}_d - \\mu_d}{s_d/\\sqrt{n}}$'),
                      `Distribution` = c('$z$','$z$', '$t(n-1)$','$t(\\min(n_1 - 1, n_2 - 1))$','$t(n_1+n_2 - 2)$','$t(n-1)$'))

kable(df, format = 'html', digits = 2,
      row.names = F, booktabs = T, escape = F)%>%
  kable_classic(full_width = F, html_font = "Cambria")%>%kable_styling(bootstrap_options = 'striped')

```

Despite significantly expanding the our statistical tools for inference we are still quite limited in our ability to analyze qualitative responses. Our tests for a proportion are useful for comparing a single category of a qualitative variable across one or two samples, but what if we are interested in comparing multiple categories across more than population? We will now explore some of the common tools for analyzing qualitative data. The inference techniques for qualitative variables are generally concerned with comparing a response variable with two or more categories across an explanatory variable with two or more groupings by exploring how the conditional distribution of the response varies across the groups in the explanatory variable. In other words, these inference procedures are designed to analyze the statistical association between two multi-category qualitative variables. 

Such problems are typically represented as a table where the rows represent the groupings of the explanatory variable and columns represent the categories of the response variable - often referred to as "two-way tables". 


### The Chi-square goodness of fit test

**Example: Gregor Mendels Peas** - Gregor Mendel conducted a study in which he crossed pea plants. The plants he crossed had the alleles (i.e., a form or version of a gene) for both yellow $Y$ and green peas $y$ — a trait controlled by a single locus. He believed two of his laws applied here: the Law of Segregation and the Law of Dominance. These laws would determine the probabilities of certain genotypes. This can be summarized by a Punnett square

```{r, echo=FALSE, warning=F, message=F}
set.seed(123)

df = cbind.data.frame(c('$YY = 0.25$', '$Yy = 0.25$'),
                      c('$Yy = 0.25$', '$yy = 0.25$'))
row.names(df) = c('Yellow','Green')

kable(df, format = 'html', digits = 2, col.names = c('Yellow', 'Green'),
      row.names = F, booktabs = T, escape = F)%>%
  kable_classic(full_width = F, html_font = "Cambria")%>%kable_styling(bootstrap_options = 'striped')


```

  * If Mendel’s Laws are true, what do they imply about the probability distribution for these four outcomes (i.e., $YY$, $Yy$, $yY$, or $yy$)? And what does this imply about the probability distribution of color (i.e., yellow or green) ?


Mendel bred $8023$ offspring. Of these, $6022$ were yellow, and $2001$ were green. Do his laws “fit” the data? That is, does the trait of color in pea plants exhibit what we would call Mendelian inheritance?



```{r, echo=FALSE, warning=F, message=F}
set.seed(123)

df = cbind.data.frame(`Color` = c('Yellow', 'Green'),
                      `Expected Frequency` = c(0.75, 0.25),
                      `Observed Count` = c(6022, 2001),
                      `Observed Frequency` = c(6022/8023, 2001/8023))

kable(df, format = 'html', digits = 4,
      row.names = F, booktabs = T, escape = F)%>%
  kable_classic(full_width = F, html_font = "Cambria")%>%kable_styling(bootstrap_options = 'striped')


```

The above problem amounts to comparing the observed frequencies of each color to the frequencies that we would expect under the Mendelian model of inheritance. In other words, we are comparing our "observed" distribution to a distribution we would expect. This type of comparison can be accomplished using a $\chi^2$ "goodness of fit" test.

In this case the null hypothesis is that the offspring of the pea plants follows Mendelian inheritance or 

\[H_0: p_{yellow} = 0.75; p_{green} = 0.25 \]

The alternative is that frequency of each color do not follow the frequencies defined in the null. To generalize for a categorical variable with $k$ possible outcomes the null becomes $H_0: p_i = c_i; \forall i\in[1:k]$ and $H_A:$ at least one $p_i \neq c_i$. 

The above hypothesis test uses $\chi^2$ test statistic defined as

\[X^2 = \sum_{i =1}^k \frac{(\text{observed count}_i - \text{expected count}_i)^2}{\text{expected count}_i} \]

  * $k$ is the number of possible outcomes
  
  * the observed count is the number of observations we observed with outcome $i$
  
  * the expected count is the number of observations we expect to have outcome $i$ which is calculated under the null hypothesis as $np_i$
  
  * We can think of this calculated as measuring the average distance from the observed model to the model we expect under the null.
  
$X^2$ can take on values between $0$ and positive $\infty$. A value of zero means the observed model exactly follows the expected model. Values greater than zero indicate a deviation from the expected model. Large values of $X^2$ indicate evidence against the null hypothesis 
  
Referring back to Mendel's pea plants we compute the expected number of yellow pea plants as $8023\times 0.75 = 6017.25$ and the expected number of green pea plants to be $8023\times 0.25 = 2005.75$. The test statistic is 

\[X^2 = \frac{(6022 - 6017.25)^2}{6017.25} +\frac{(2001 - 2005.75)}{2005.75} \]

\[ = 0.0037 + 0.0112  \]

\[ \approx 0.015\]

#### The Chi-square distribution

To convert the above statistic into a $p$-value we need to know its sampling distribution. The statistic $X^2$ is called a $\chi^2$ test statistic because its sampling distribution follows a special type of probability distribution called the $\chi^2$ distribution. Kike the $t$ distribution, the $\chi^2$ distributions form a family of distributions controlled by a single parameter - the degrees of freedom. We will use the notation $\chi^2(df)$ to depict a specific member of this family. For the goodness of fit test the the test statistic $X^2$ follows a $\chi^2$ distribution with $k-1$ degrees of freedom: 


```{r, echo=FALSE, warning=F, message=F, fig.width=10, fig.height=6, results = 'hide'}

x = seq(0, 20, 0.01)
df1 = dchisq(x, 1)
df2 = dchisq(x, 2)
df4 = dchisq(x, 4)
df6 = dchisq(x, 6)
df8 = dchisq(x, 8)
#df12 = dchisq(x, 12)
df = cbind.data.frame(`$\\chi^2$` = rep(x, 5),
                      `Density` = c(df1, df2, df4, df6, df8),# df12),
                      `Degrees of freedom` = c(rep('df = 1', length(x)),
                                               rep('df = 2', length(x)),
                                               rep('df = 4', length(x)),
                                               rep('df = 6', length(x)),
                                               rep('df = 8', length(x))
                                               #rep('df = 12', length(x))
                                               ))

ggplot(data = df, aes(x = `$\\chi^2$`, y = Density, color = `Degrees of freedom`))+
  geom_line(size = 1.5)+
  scale_y_continuous(limits = c(0, 0.5))+
  theme_bw()+
  theme(axis.title = element_text(size = 12),
        axis.text = element_text(size = 12))+
  xlab(TeX('$\\chi^2$'))+
  ggtitle(TeX('The $\\chi^2$ Distribution'))

```

 * As we did the $t$ distribution we can look up probabilities from a $chi^2$ table:

```{r, echo=F, message=F, warning=F}
DF = c(1:30, 40, 50, 100)
probs = rbind.data.frame(cbind.data.frame(c('$DF$', DF), 
                         c('',round(qchisq(1-0.5/2, DF), 3)), c('',round(qchisq(1-0.4/2, DF),3)),
                         c('',round(qchisq(1-0.3/2, DF),3)), c('',round(qchisq(1-0.25/2, DF),3)), 
                         c('',round(qchisq(1-0.2/2, DF), 3)), c('',round(qchisq(1-0.15/2, DF),3)), 
                         c('',round(qchisq(1-0.1/2, DF),3)), c('',round(qchisq(1-0.05/2, DF),3)),
                         c('',round(qchisq(1-0.01/2, DF),3)), c('',round(qchisq(1 - 0.005/2, DF),3)),
                         c('',round(qchisq(1 - 0.001/2, DF),3))),
                         c('Z-score', round(qnorm(1-c(0.5, 0.4, 0.3, 0.25, 0.2, 0.15, 0.1, 0.05, 0.01, 0.005, 0.001)/2),3)),
                         c('Confidence Level:', 
                           paste0('$',100*(1-c(0.5, 0.4, 0.3, 0.25, 0.2, 0.15, 0.1, 0.05, 0.01, 0.005, 0.001)), '\\%$')))
                        

df = rbind.data.frame(probs)

kable(df, format = 'html', digits = 2, col.names = c('Upper tail', 0.25, 0.2, 0.15, 0.125, 0.1, 0.075, 0.05, 0.025, 0.005, 0.0025, 0.0005),
      row.names = F, booktabs = F, escape = F)%>%
  kable_classic(full_width = F, html_font = "Cambria")%>%kable_styling(bootstrap_options = 'striped')

```






<br>
<br>
<br>
<br>

### References











































